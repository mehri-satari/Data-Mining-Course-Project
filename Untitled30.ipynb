{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehri-satari/Data-Mining-Course-Project/blob/main/Untitled30.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD6NlmJVw8ua",
        "outputId": "6de96aaf-29d6-40d8-c61a-83dea1ee7862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m125.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "torch cuda available: False\n",
            "ultralytics: 8.3.242\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 0 — Colab installs + imports + Drive mount\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install ultralytics opencv-python pillow tqdm av2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, math, json, time, shutil, re\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, List, Optional, Any, Set\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from av2.utils import io as io_utils\n",
        "\n",
        "print(\"torch cuda available:\", torch.cuda.is_available())\n",
        "print(\"ultralytics:\", __import__(\"ultralytics\").__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 1 — Log IDs + find AV2 root (auto)\n",
        "# ============================================================\n",
        "\n",
        "LOG_IDS = [\n",
        "    \"0526e68e-2ff1-3e53-b0f8-45df02e45a93\",\n",
        "    \"04973bcf-fc64-367c-9642-6d6c5f363b61\",\n",
        "    \"03fba633-8085-30bc-b675-687a715536ac\",\n",
        "    \"03b2cf2d-fb61-36fe-936f-36bbf197a8ac\",\n",
        "    \"0322b098-7e42-34db-bcec-9a4d072191e9\",\n",
        "    \"022af476-9937-3e70-be52-f65420d52703\",\n",
        "    \"01bb304d-7bd8-35f8-bbef-7086b688e35e\",\n",
        "    \"00a6ffc1-6ce9-3bc3-a060-6006e9893a1a\",\n",
        "]\n",
        "\n",
        "def find_av2_root_by_log_ids(\n",
        "    log_ids,\n",
        "    search_roots=(Path(\"/content/drive/MyDrive\"), Path(\"/content/drive/Shareddrives\")),\n",
        "    max_matches_per_root=10\n",
        ") -> Path:\n",
        "    first = log_ids[0]\n",
        "    for root in search_roots:\n",
        "        if not root.exists():\n",
        "            continue\n",
        "        candidates = []\n",
        "        for p in root.rglob(first):\n",
        "            if p.is_dir():\n",
        "                candidates.append(p)\n",
        "                if len(candidates) >= max_matches_per_root:\n",
        "                    break\n",
        "\n",
        "        for log_dir in candidates:\n",
        "            av2_root = log_dir.parent\n",
        "            ok = True\n",
        "            for lid in log_ids:\n",
        "                lid_dir = av2_root / lid\n",
        "                if not lid_dir.is_dir():\n",
        "                    ok = False; break\n",
        "                if not (lid_dir / \"annotations.feather\").exists():\n",
        "                    ok = False; break\n",
        "                if not (lid_dir / \"calibration\" / \"intrinsics.feather\").exists():\n",
        "                    ok = False; break\n",
        "                if not (lid_dir / \"calibration\" / \"egovehicle_SE3_sensor.feather\").exists():\n",
        "                    ok = False; break\n",
        "            if ok:\n",
        "                return av2_root\n",
        "\n",
        "    raise FileNotFoundError(\"Could not locate AV2 root folder in Drive.\")\n",
        "\n",
        "AV2_ROOT = find_av2_root_by_log_ids(LOG_IDS)\n",
        "print(\"✅ Found AV2_ROOT:\", AV2_ROOT)\n"
      ],
      "metadata": {
        "id": "oCbNH0MjxPBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 2 — Global configuration\n",
        "# ============================================================\n",
        "\n",
        "OUT_ROOT = Path(\"/content/drive/MyDrive/av2_redundancy_yolo_multi_logs\")\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "SPLIT_SEED = 7\n",
        "MAX_TS_DIFF_NS = 50_000_000  # 50ms\n",
        "\n",
        "TAU_BUILD_LIST = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "TAUS_REPORTED  = [0.5, 0.6]     # multi-seed only for these\n",
        "\n",
        "BASELINE_TAU = 1e9  # effectively \"no pruning\" under your rule\n",
        "\n",
        "IMGSZ = 640\n",
        "BATCH = 16\n",
        "\n",
        "# --------- IMPORTANT GUARDS ----------\n",
        "FORCE_REBUILD_DATASETS = False   # if True: rebuild baseline/pruned folders (expensive)\n",
        "FORCE_RETRAIN_MODELS   = False   # if True: retrain even if weights exist\n",
        "\n",
        "print(\"OUT_ROOT:\", OUT_ROOT)\n",
        "print(\"TAU_BUILD_LIST:\", TAU_BUILD_LIST)\n",
        "print(\"TAUS_REPORTED:\", TAUS_REPORTED)\n",
        "print(\"FORCE_REBUILD_DATASETS:\", FORCE_REBUILD_DATASETS)\n",
        "print(\"FORCE_RETRAIN_MODELS:\", FORCE_RETRAIN_MODELS)\n"
      ],
      "metadata": {
        "id": "bV1wFk5pxO-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 3 — Geometry utilities\n",
        "# ============================================================\n",
        "\n",
        "def quat_to_rotmat(qw, qx, qy, qz) -> np.ndarray:\n",
        "    q = np.array([qw, qx, qy, qz], dtype=np.float64)\n",
        "    q = q / (np.linalg.norm(q) + 1e-12)\n",
        "    w, x, y, z = q\n",
        "    R = np.array([\n",
        "        [1-2*(y*y+z*z), 2*(x*y - z*w), 2*(x*z + y*w)],\n",
        "        [2*(x*y + z*w), 1-2*(x*x+z*z), 2*(y*z - x*w)],\n",
        "        [2*(x*z - z*w*0 + 0), 0, 0]  # placeholder to avoid confusion\n",
        "    ], dtype=np.float64)\n",
        "    # Fix the accidental placeholder row; keep your original correct form:\n",
        "    R = np.array([\n",
        "        [1-2*(y*y+z*z), 2*(x*y - z*w), 2*(x*z + y*w)],\n",
        "        [2*(x*y + z*w), 1-2*(x*x+z*z), 2*(y*z - x*w)],\n",
        "        [2*(x*z - y*w), 2*(y*z + x*w), 1-2*(x*x+y*y)],\n",
        "    ], dtype=np.float64)\n",
        "    return R\n",
        "\n",
        "@dataclass\n",
        "class SE3:\n",
        "    R: np.ndarray\n",
        "    t: np.ndarray\n",
        "    def inverse(self) -> \"SE3\":\n",
        "        R_inv = self.R.T\n",
        "        t_inv = -R_inv @ self.t\n",
        "        return SE3(R=R_inv, t=t_inv)\n",
        "    def transform_points(self, pts: np.ndarray) -> np.ndarray:\n",
        "        return (pts @ self.R.T) + self.t.reshape(1, 3)\n",
        "\n",
        "@dataclass\n",
        "class CameraIntrinsics:\n",
        "    fx: float\n",
        "    fy: float\n",
        "    cx: float\n",
        "    cy: float\n",
        "\n",
        "def build_intrinsics_dict(intr_df: pd.DataFrame) -> Dict[str, CameraIntrinsics]:\n",
        "    req = [\"sensor_name\", \"fx_px\", \"fy_px\", \"cx_px\", \"cy_px\"]\n",
        "    for c in req:\n",
        "        if c not in intr_df.columns:\n",
        "            raise ValueError(f\"Missing intrinsics column: {c}\")\n",
        "    intr = {}\n",
        "    for _, r in intr_df.iterrows():\n",
        "        intr[str(r[\"sensor_name\"])] = CameraIntrinsics(\n",
        "            fx=float(r[\"fx_px\"]), fy=float(r[\"fy_px\"]),\n",
        "            cx=float(r[\"cx_px\"]), cy=float(r[\"cy_px\"])\n",
        "        )\n",
        "    return intr\n",
        "\n",
        "def build_extrinsics_dict(extr_df: pd.DataFrame) -> Dict[str, SE3]:\n",
        "    if \"sensor_name\" not in extr_df.columns:\n",
        "        raise ValueError(\"extrinsics missing 'sensor_name'\")\n",
        "    quat_cols = [c for c in [\"qw\", \"qx\", \"qy\", \"qz\"] if c in extr_df.columns]\n",
        "    trans_cols = [c for c in [\"tx_m\", \"ty_m\", \"tz_m\"] if c in extr_df.columns]\n",
        "    extr: Dict[str, SE3] = {}\n",
        "    for _, r in extr_df.iterrows():\n",
        "        name = str(r[\"sensor_name\"])\n",
        "        if len(quat_cols) == 4 and len(trans_cols) == 3:\n",
        "            R = quat_to_rotmat(float(r[\"qw\"]), float(r[\"qx\"]), float(r[\"qy\"]), float(r[\"qz\"]))\n",
        "            t = np.array([float(r[\"tx_m\"]), float(r[\"ty_m\"]), float(r[\"tz_m\"])], dtype=np.float64)\n",
        "            extr[name] = SE3(R=R, t=t)\n",
        "        else:\n",
        "            mat_col = None\n",
        "            for cand in [\"T_egovehicle_sensor\", \"egovehicle_SE3_sensor\", \"transform_matrix\"]:\n",
        "                if cand in extr_df.columns:\n",
        "                    mat_col = cand\n",
        "                    break\n",
        "            if mat_col is None:\n",
        "                raise ValueError(\"Extrinsics format not recognized.\")\n",
        "            T = np.array(r[mat_col], dtype=np.float64).reshape(4, 4)\n",
        "            extr[name] = SE3(R=T[:3, :3], t=T[:3, 3])\n",
        "    return extr\n",
        "\n",
        "def get_col(available_cols, candidates):\n",
        "    for c in candidates:\n",
        "        if c in available_cols:\n",
        "            return c\n",
        "    raise KeyError(f\"None of {candidates} found in columns.\")\n",
        "\n",
        "def cuboid_corners_ego(row: pd.Series) -> np.ndarray:\n",
        "    cols = set(row.index)\n",
        "    cx = float(row[get_col(cols, [\"center_x\", \"tx_m\", \"x\", \"translation_x\"])])\n",
        "    cy = float(row[get_col(cols, [\"center_y\", \"ty_m\", \"y\", \"translation_y\"])])\n",
        "    cz = float(row[get_col(cols, [\"center_z\", \"tz_m\", \"z\", \"translation_z\"])])\n",
        "    length = float(row[get_col(cols, [\"length_m\", \"length\"])])\n",
        "    width  = float(row[get_col(cols, [\"width_m\", \"width\"])])\n",
        "    height = float(row[get_col(cols, [\"height_m\", \"height\"])])\n",
        "    qw = float(row[get_col(cols, [\"qw\", \"rotation_qw\"])])\n",
        "    qx = float(row[get_col(cols, [\"qx\", \"rotation_qx\"])])\n",
        "    qy = float(row[get_col(cols, [\"qy\", \"rotation_qy\"])])\n",
        "    qz = float(row[get_col(cols, [\"qz\", \"rotation_qz\"])])\n",
        "    R = quat_to_rotmat(qw, qx, qy, qz)\n",
        "    center = np.array([cx, cy, cz], dtype=np.float64)\n",
        "\n",
        "    l2, w2, h2 = length/2, width/2, height/2\n",
        "    corners_local = np.array([\n",
        "        [ l2,  w2,  h2],[ l2, -w2,  h2],[-l2, -w2,  h2],[-l2,  w2,  h2],\n",
        "        [ l2,  w2, -h2],[ l2, -w2, -h2],[-l2, -w2, -h2],[-l2,  w2, -h2],\n",
        "    ], dtype=np.float64)\n",
        "    return (corners_local @ R.T) + center.reshape(1, 3)\n",
        "\n",
        "@dataclass\n",
        "class Box2D:\n",
        "    xmin: float\n",
        "    ymin: float\n",
        "    xmax: float\n",
        "    ymax: float\n",
        "    bcs: float\n",
        "\n",
        "def project_points_to_image(pts_cam: np.ndarray, intr: CameraIntrinsics) -> np.ndarray:\n",
        "    x, y, z = pts_cam[:,0], pts_cam[:,1], pts_cam[:,2]\n",
        "    eps = 1e-9\n",
        "    u = intr.fx*(x/(z+eps)) + intr.cx\n",
        "    v = intr.fy*(y/(z+eps)) + intr.cy\n",
        "    return np.stack([u,v,z], axis=1)\n",
        "\n",
        "def bbox_and_bcs_from_cuboid(corners_ego, intr, T_sensor_ego, img_w, img_h) -> Optional[Box2D]:\n",
        "    corners_cam = T_sensor_ego.transform_points(corners_ego)\n",
        "    if np.all(corners_cam[:,2] <= 0.1):\n",
        "        return None\n",
        "    uvz = project_points_to_image(corners_cam, intr)\n",
        "    u, v, z = uvz[:,0], uvz[:,1], uvz[:,2]\n",
        "    valid = z > 0.1\n",
        "    if valid.sum() < 2:\n",
        "        return None\n",
        "    u_full, v_full = u[valid], v[valid]\n",
        "    xmin_full, xmax_full = float(u_full.min()), float(u_full.max())\n",
        "    ymin_full, ymax_full = float(v_full.min()), float(v_full.max())\n",
        "    full_w, full_h = max(0.0, xmax_full-xmin_full), max(0.0, ymax_full-ymin_full)\n",
        "    area_full = full_w*full_h\n",
        "    if area_full <= 1e-6:\n",
        "        return None\n",
        "    xmin_clip = max(0.0, min(img_w-1.0, xmin_full))\n",
        "    xmax_clip = max(0.0, min(img_w-1.0, xmax_full))\n",
        "    ymin_clip = max(0.0, min(img_h-1.0, ymin_full))\n",
        "    ymax_clip = max(0.0, min(img_h-1.0, ymax_full))\n",
        "    clip_w, clip_h = max(0.0, xmax_clip-xmin_clip), max(0.0, ymax_clip-ymin_clip)\n",
        "    area_clip = clip_w*clip_h\n",
        "    bcs = float(area_clip/area_full)\n",
        "    if area_clip <= 1.0:\n",
        "        return None\n",
        "    return Box2D(xmin=xmin_clip, ymin=ymin_clip, xmax=xmax_clip, ymax=ymax_clip, bcs=bcs)\n",
        "\n",
        "def yolo_line_from_box(box: Box2D, cls_id: int, img_w: int, img_h: int) -> str:\n",
        "    cx = ((box.xmin+box.xmax)/2.0)/img_w\n",
        "    cy = ((box.ymin+box.ymax)/2.0)/img_h\n",
        "    w  = (box.xmax-box.xmin)/img_w\n",
        "    h  = (box.ymax-box.ymin)/img_h\n",
        "    cx = min(max(float(cx), 0.0), 1.0)\n",
        "    cy = min(max(float(cy), 0.0), 1.0)\n",
        "    w  = min(max(float(w),  0.0), 1.0)\n",
        "    h  = min(max(float(h),  0.0), 1.0)\n",
        "    return f\"{cls_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\"\n"
      ],
      "metadata": {
        "id": "m8lPJl7qxO7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 4 — Camera image indexing + overlap pairs\n",
        "# ============================================================\n",
        "\n",
        "def find_camera_root(scene_path: Path) -> Path:\n",
        "    candidates = [\n",
        "        scene_path / \"sensors\" / \"cameras\",\n",
        "        scene_path / \"sensor\" / \"cameras\",\n",
        "        scene_path / \"cameras\",\n",
        "    ]\n",
        "    for p in candidates:\n",
        "        if p.exists():\n",
        "            return p\n",
        "    raise FileNotFoundError(f\"Cannot find camera root under {scene_path}\")\n",
        "\n",
        "def parse_timestamp_from_filename(p: Path) -> Optional[int]:\n",
        "    stem = p.stem\n",
        "    return int(stem) if stem.isdigit() else None\n",
        "\n",
        "def index_images(cam_root: Path, cameras: List[str]) -> Dict[str, Dict[int, Path]]:\n",
        "    idx = {}\n",
        "    for cam in cameras:\n",
        "        cam_dir = cam_root / cam\n",
        "        if not cam_dir.exists():\n",
        "            idx[cam] = {}; continue\n",
        "        ts_map = {}\n",
        "        for ext in [\"*.jpg\",\"*.jpeg\",\"*.png\"]:\n",
        "            for p in cam_dir.glob(ext):\n",
        "                ts = parse_timestamp_from_filename(p)\n",
        "                if ts is not None:\n",
        "                    ts_map[ts] = p\n",
        "        idx[cam] = ts_map\n",
        "    return idx\n",
        "\n",
        "def nearest_timestamp(target: int, available_sorted: List[int], max_diff_ns: int = 50_000_000) -> Optional[int]:\n",
        "    if not available_sorted:\n",
        "        return None\n",
        "    arr = np.array(available_sorted, dtype=np.int64)\n",
        "    i = int(np.searchsorted(arr, target))\n",
        "    cand = []\n",
        "    if i < len(arr): cand.append(int(arr[i]))\n",
        "    if i > 0: cand.append(int(arr[i-1]))\n",
        "    best = min(cand, key=lambda x: abs(int(x)-int(target)))\n",
        "    return int(best) if abs(int(best)-int(target)) <= max_diff_ns else None\n",
        "\n",
        "def wrap_pi(a: float) -> float:\n",
        "    return float((a + np.pi) % (2*np.pi) - np.pi)\n",
        "\n",
        "def fov_segments(center: float, hfov: float):\n",
        "    a1 = wrap_pi(center - hfov/2)\n",
        "    a2 = wrap_pi(center + hfov/2)\n",
        "    if a1 <= a2: return [(a1,a2)]\n",
        "    return [(a1,np.pi),(-np.pi,a2)]\n",
        "\n",
        "def seg_overlap(s1, s2) -> float:\n",
        "    left = max(s1[0], s2[0]); right = min(s1[1], s2[1])\n",
        "    return max(0.0, right-left)\n",
        "\n",
        "def circular_overlap(center1, hfov1, center2, hfov2) -> float:\n",
        "    segs1 = fov_segments(center1,hfov1)\n",
        "    segs2 = fov_segments(center2,hfov2)\n",
        "    ov = 0.0\n",
        "    for a in segs1:\n",
        "        for b in segs2:\n",
        "            ov += seg_overlap(a,b)\n",
        "    return float(min(ov, min(hfov1,hfov2)))\n",
        "\n",
        "def camera_yaw_center_in_ego(T_ego_sensor: SE3) -> float:\n",
        "    forward_cam = np.array([0.0,0.0,1.0], dtype=np.float64)\n",
        "    forward_ego = T_ego_sensor.R @ forward_cam\n",
        "    return float(np.arctan2(forward_ego[1], forward_ego[0]))\n",
        "\n",
        "def hfov_from_intrinsics(intr: CameraIntrinsics, img_w: int) -> float:\n",
        "    return float(2.0*np.arctan(img_w/(2.0*intr.fx)))\n",
        "\n",
        "def compute_overlap_pairs(cameras, INTR, T_EGO_SENSOR, IMG_INDEX, min_overlap_deg=5.0):\n",
        "    min_overlap = math.radians(min_overlap_deg)\n",
        "    cam_sizes = {}\n",
        "    for cam in cameras:\n",
        "        ts_map = IMG_INDEX.get(cam, {})\n",
        "        if not ts_map: continue\n",
        "        any_path = next(iter(ts_map.values()))\n",
        "        with Image.open(any_path) as im:\n",
        "            cam_sizes[cam] = im.size\n",
        "\n",
        "    cam_info = {}\n",
        "    for cam in cameras:\n",
        "        if cam not in cam_sizes or cam not in INTR or cam not in T_EGO_SENSOR: continue\n",
        "        W,_ = cam_sizes[cam]\n",
        "        yaw = camera_yaw_center_in_ego(T_EGO_SENSOR[cam])\n",
        "        hfov = hfov_from_intrinsics(INTR[cam], W)\n",
        "        cam_info[cam] = (yaw,hfov)\n",
        "\n",
        "    cams = list(cam_info.keys())\n",
        "    pairs = []\n",
        "    for i in range(len(cams)):\n",
        "        for j in range(i+1,len(cams)):\n",
        "            c1,c2 = cams[i], cams[j]\n",
        "            yaw1,hfov1 = cam_info[c1]\n",
        "            yaw2,hfov2 = cam_info[c2]\n",
        "            ov = circular_overlap(yaw1,hfov1,yaw2,hfov2)\n",
        "            if ov >= min_overlap:\n",
        "                pairs.append((c1,c2,ov))\n",
        "    pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "    return pairs\n"
      ],
      "metadata": {
        "id": "I6Wby99axO48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 5 — Load metadata for ALL logs + GLOBAL class map\n",
        "# ============================================================\n",
        "\n",
        "def load_initial_data(scene_path: Path):\n",
        "    ann_df  = io_utils.read_feather(scene_path / \"annotations.feather\")\n",
        "    intr_df = io_utils.read_feather(scene_path / \"calibration\" / \"intrinsics.feather\")\n",
        "    extr_df = io_utils.read_feather(scene_path / \"calibration\" / \"egovehicle_SE3_sensor.feather\")\n",
        "    return ann_df, intr_df, extr_df\n",
        "\n",
        "ANN_BY_LOG: Dict[str, pd.DataFrame] = {}\n",
        "all_categories: Set[str] = set()\n",
        "\n",
        "CATEGORY_COL = \"category\"\n",
        "\n",
        "for log_id in LOG_IDS:\n",
        "    scene_path = AV2_ROOT / log_id\n",
        "    ann_df, _, _ = load_initial_data(scene_path)\n",
        "    ANN_BY_LOG[log_id] = ann_df\n",
        "\n",
        "    if CATEGORY_COL not in ann_df.columns:\n",
        "        raise ValueError(f\"{log_id}: missing '{CATEGORY_COL}'\")\n",
        "\n",
        "    cats = ann_df[CATEGORY_COL].dropna().astype(str).unique().tolist()\n",
        "    all_categories.update(cats)\n",
        "\n",
        "NAMES = sorted(list(all_categories))\n",
        "CLASS_MAP = {c: i for i, c in enumerate(NAMES)}\n",
        "\n",
        "print(\"GLOBAL Num classes:\", len(NAMES))\n",
        "print(\"Example class map:\", list(CLASS_MAP.items())[:10])\n"
      ],
      "metadata": {
        "id": "7shP5ggjxO15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 6 — Shared train/val split across ALL logs\n",
        "# ============================================================\n",
        "\n",
        "def make_train_val_split_by_log_timestamp(ann_by_log, train_ratio=0.8, seed=7):\n",
        "    keys = []\n",
        "    for log_id, ann_df in ann_by_log.items():\n",
        "        if \"timestamp_ns\" not in ann_df.columns:\n",
        "            raise ValueError(f\"{log_id}: missing timestamp_ns\")\n",
        "        for ts in ann_df[\"timestamp_ns\"].dropna().astype(np.int64).unique():\n",
        "            keys.append((log_id, int(ts)))\n",
        "    rng = np.random.RandomState(seed)\n",
        "    rng.shuffle(keys)\n",
        "    n_train = int(len(keys)*train_ratio)\n",
        "    return set(keys[:n_train]), set(keys[n_train:])\n",
        "\n",
        "TRAIN_KEYS, VAL_KEYS = make_train_val_split_by_log_timestamp(ANN_BY_LOG, 0.8, SPLIT_SEED)\n",
        "print(\"Train keys:\", len(TRAIN_KEYS), \"| Val keys:\", len(VAL_KEYS))\n"
      ],
      "metadata": {
        "id": "bNOGQdDrxBs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 7 — Build YOLO dataset (baseline + pruned) WITH EXISTS GUARD\n",
        "# ============================================================\n",
        "\n",
        "def dataset_ready(dataset_dir: Path) -> bool:\n",
        "    return (\n",
        "        (dataset_dir / \"data.yaml\").exists()\n",
        "        and (dataset_dir / \"images\" / \"train\").exists()\n",
        "        and (dataset_dir / \"images\" / \"val\").exists()\n",
        "        and (dataset_dir / \"labels\" / \"train\").exists()\n",
        "        and (dataset_dir / \"labels\" / \"val\").exists()\n",
        "    )\n",
        "\n",
        "def save_build_info(info: dict, dataset_dir: Path):\n",
        "    p = dataset_dir / \"_build_info.json\"\n",
        "    with open(p, \"w\") as f:\n",
        "        json.dump(info, f, indent=2)\n",
        "\n",
        "def load_build_info(dataset_dir: Path) -> Optional[dict]:\n",
        "    p = dataset_dir / \"_build_info.json\"\n",
        "    if p.exists():\n",
        "        return json.loads(p.read_text())\n",
        "    return None\n",
        "\n",
        "def build_yolo_from_av2_logs(\n",
        "    log_ids, av2_root, ann_by_log, out_root, tau_bcs,\n",
        "    train_keys, val_keys, class_map, names,\n",
        "    max_ts_diff_ns=50_000_000, drop_empty_images=False,\n",
        "    force_rebuild=False\n",
        "):\n",
        "    dataset_dir = Path(out_root)\n",
        "\n",
        "    # ---------- EXISTS GUARD ----------\n",
        "    if (not force_rebuild) and dataset_ready(dataset_dir):\n",
        "        cached = load_build_info(dataset_dir)\n",
        "        if cached is not None:\n",
        "            print(f\"✅ [SKIP BUILD] Using existing dataset at: {dataset_dir}\")\n",
        "            return cached\n",
        "        else:\n",
        "            print(f\"✅ [SKIP BUILD] Dataset exists (no build_info); using: {dataset_dir}\")\n",
        "            return {\"dataset_dir\": dataset_dir, \"data_yaml\": dataset_dir/\"data.yaml\"}\n",
        "\n",
        "    # If rebuilding, clear dir\n",
        "    if dataset_dir.exists():\n",
        "        shutil.rmtree(dataset_dir)\n",
        "    dataset_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for split in [\"train\",\"val\"]:\n",
        "        (dataset_dir/\"images\"/split).mkdir(parents=True, exist_ok=True)\n",
        "        (dataset_dir/\"labels\"/split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    total_candidate_labels = 0\n",
        "    total_deleted_labels = 0\n",
        "    total_unique_3d_objects = set()\n",
        "\n",
        "    for log_id in log_ids:\n",
        "        scene_path = av2_root / log_id\n",
        "        ann_df = ann_by_log[log_id]\n",
        "\n",
        "        _, intr_df, extr_df = load_initial_data(scene_path)\n",
        "        INTR = build_intrinsics_dict(intr_df)\n",
        "        T_EGO_SENSOR = build_extrinsics_dict(extr_df)                 # sensor -> ego\n",
        "        T_SENSOR_EGO = {k: v.inverse() for k,v in T_EGO_SENSOR.items()}  # ego -> sensor\n",
        "\n",
        "        CAMERAS = intr_df[\"sensor_name\"].astype(str).unique().tolist()\n",
        "        CAM_ROOT = find_camera_root(scene_path)\n",
        "        IMG_INDEX = index_images(CAM_ROOT, CAMERAS)\n",
        "        OVERLAP_PAIRS = compute_overlap_pairs(CAMERAS, INTR, T_EGO_SENSOR, IMG_INDEX, min_overlap_deg=5.0)\n",
        "\n",
        "        cameras = [c for c in INTR.keys() if c in IMG_INDEX and len(IMG_INDEX[c])>0]\n",
        "        if not cameras:\n",
        "            print(f\"[WARN] {log_id}: no cameras with images. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        cam_size = {}\n",
        "        for cam in cameras:\n",
        "            any_path = next(iter(IMG_INDEX[cam].values()))\n",
        "            with Image.open(any_path) as im:\n",
        "                cam_size[cam] = im.size\n",
        "        cam_ts_sorted = {cam: sorted(IMG_INDEX[cam].keys()) for cam in cameras}\n",
        "\n",
        "        keys_for_log = sorted(list({k for k in (train_keys|val_keys) if k[0]==log_id}), key=lambda x: x[1])\n",
        "\n",
        "        for (_, ts) in tqdm(keys_for_log, desc=f\"Build {log_id[:8]} tau={tau_bcs}\", leave=False):\n",
        "            split = \"train\" if (log_id, ts) in train_keys else (\"val\" if (log_id, ts) in val_keys else None)\n",
        "            if split is None:\n",
        "                continue\n",
        "\n",
        "            ann_rows = ann_df[ann_df[\"timestamp_ns\"] == ts]\n",
        "            if ann_rows.empty:\n",
        "                continue\n",
        "\n",
        "            per_cam_boxes = {cam:{} for cam in cameras}  # cam -> track -> (box,cls,ts_img,img_path,W,H)\n",
        "\n",
        "            for _, row in ann_rows.iterrows():\n",
        "                track = str(row[\"track_uuid\"])\n",
        "                cat = row[CATEGORY_COL]\n",
        "                if pd.isna(cat):\n",
        "                    continue\n",
        "                cat_str = str(cat)\n",
        "                if cat_str not in class_map:\n",
        "                    continue\n",
        "                cls_id = int(class_map[cat_str])\n",
        "\n",
        "                corners = cuboid_corners_ego(row)\n",
        "\n",
        "                any_projection = False\n",
        "                for cam in cameras:\n",
        "                    ts_img = nearest_timestamp(ts, cam_ts_sorted[cam], max_diff_ns=max_ts_diff_ns)\n",
        "                    if ts_img is None:\n",
        "                        continue\n",
        "                    img_path = IMG_INDEX[cam][ts_img]\n",
        "                    W,H = cam_size[cam]\n",
        "\n",
        "                    box = bbox_and_bcs_from_cuboid(\n",
        "                        corners_ego=corners,\n",
        "                        intr=INTR[cam],\n",
        "                        T_sensor_ego=T_SENSOR_EGO[cam],  # ego -> camera\n",
        "                        img_w=W, img_h=H\n",
        "                    )\n",
        "                    if box is None:\n",
        "                        continue\n",
        "\n",
        "                    per_cam_boxes[cam][track] = (box, cls_id, ts_img, img_path, W, H)\n",
        "                    any_projection = True\n",
        "\n",
        "                if any_projection:\n",
        "                    total_unique_3d_objects.add((log_id, int(ts), track))\n",
        "\n",
        "            candidates_this_ts = sum(len(per_cam_boxes[cam]) for cam in cameras)\n",
        "            total_candidate_labels += candidates_this_ts\n",
        "\n",
        "            # ---- pruning decision (your original) ----\n",
        "            to_drop = set()\n",
        "            for camA, camB, _ in OVERLAP_PAIRS:\n",
        "                if camA not in per_cam_boxes or camB not in per_cam_boxes:\n",
        "                    continue\n",
        "                common_tracks = set(per_cam_boxes[camA].keys()) & set(per_cam_boxes[camB].keys())\n",
        "                for track in common_tracks:\n",
        "                    boxA, clsA, tsA, _, _, _ = per_cam_boxes[camA][track]\n",
        "                    boxB, clsB, tsB, _, _, _ = per_cam_boxes[camB][track]\n",
        "                    if clsA != clsB:\n",
        "                        continue\n",
        "                    if abs(boxA.bcs - boxB.bcs) > tau_bcs:\n",
        "                        if boxA.bcs >= boxB.bcs:\n",
        "                            to_drop.add((camB, track, tsB))\n",
        "                        else:\n",
        "                            to_drop.add((camA, track, tsA))\n",
        "\n",
        "            total_deleted_labels += len(to_drop)\n",
        "\n",
        "            for cam in cameras:\n",
        "                entries = list(per_cam_boxes[cam].items())\n",
        "                if not entries:\n",
        "                    continue\n",
        "                _, (_, _, ts_img, img_path, W, H) = entries[0]\n",
        "                out_img_name = f\"{log_id}_{cam}_{ts_img}.jpg\"\n",
        "                out_lbl_name = f\"{log_id}_{cam}_{ts_img}.txt\"\n",
        "\n",
        "                lines = []\n",
        "                for track, (box, cls_id, ts_img2, _, W2, H2) in per_cam_boxes[cam].items():\n",
        "                    if (cam, track, ts_img2) in to_drop:\n",
        "                        continue\n",
        "                    lines.append(yolo_line_from_box(box, cls_id, W2, H2))\n",
        "\n",
        "                if drop_empty_images and len(lines)==0:\n",
        "                    continue\n",
        "\n",
        "                shutil.copy(img_path, dataset_dir/\"images\"/split/out_img_name)\n",
        "                with open(dataset_dir/\"labels\"/split/out_lbl_name, \"w\") as f:\n",
        "                    f.write(\"\\n\".join(lines))\n",
        "\n",
        "    data_yaml = dataset_dir / \"data.yaml\"\n",
        "    yaml_text = (\n",
        "        f\"path: {dataset_dir}\\n\"\n",
        "        f\"train: images/train\\n\"\n",
        "        f\"val: images/val\\n\"\n",
        "        f\"nc: {len(names)}\\n\"\n",
        "        f\"names: {json.dumps(names)}\\n\"\n",
        "    )\n",
        "    with open(data_yaml, \"w\") as f:\n",
        "        f.write(yaml_text)\n",
        "\n",
        "    info = {\n",
        "        \"dataset_dir\": str(dataset_dir),\n",
        "        \"data_yaml\": str(data_yaml),\n",
        "        \"total_candidate_labels_before_pruning\": int(total_candidate_labels),\n",
        "        \"total_deleted_label_instances\": int(total_deleted_labels),\n",
        "        \"total_unique_3d_objects_seen\": int(len(total_unique_3d_objects)),\n",
        "    }\n",
        "    save_build_info(info, dataset_dir)\n",
        "\n",
        "    return info\n",
        "\n",
        "# Build baseline + pruned (safe in Run All)\n",
        "baseline_info = build_yolo_from_av2_logs(\n",
        "    log_ids=LOG_IDS,\n",
        "    av2_root=AV2_ROOT,\n",
        "    ann_by_log=ANN_BY_LOG,\n",
        "    out_root=OUT_ROOT / \"baseline_unpruned\",\n",
        "    tau_bcs=BASELINE_TAU,\n",
        "    train_keys=TRAIN_KEYS,\n",
        "    val_keys=VAL_KEYS,\n",
        "    class_map=CLASS_MAP,\n",
        "    names=NAMES,\n",
        "    max_ts_diff_ns=MAX_TS_DIFF_NS,\n",
        "    drop_empty_images=False,\n",
        "    force_rebuild=FORCE_REBUILD_DATASETS\n",
        ")\n",
        "print(\"✅ Baseline ready:\", baseline_info[\"dataset_dir\"])\n",
        "\n",
        "PRUNED_INFOS = {}\n",
        "for tau in TAU_BUILD_LIST:\n",
        "    info = build_yolo_from_av2_logs(\n",
        "        log_ids=LOG_IDS,\n",
        "        av2_root=AV2_ROOT,\n",
        "        ann_by_log=ANN_BY_LOG,\n",
        "        out_root=OUT_ROOT / f\"pruned_tau{tau:.1f}\",\n",
        "        tau_bcs=float(tau),\n",
        "        train_keys=TRAIN_KEYS,\n",
        "        val_keys=VAL_KEYS,\n",
        "        class_map=CLASS_MAP,\n",
        "        names=NAMES,\n",
        "        max_ts_diff_ns=MAX_TS_DIFF_NS,\n",
        "        drop_empty_images=False,\n",
        "        force_rebuild=FORCE_REBUILD_DATASETS\n",
        "    )\n",
        "    PRUNED_INFOS[tau] = info\n",
        "    print(f\"✅ Pruned tau={tau:.1f} ready:\", info[\"dataset_dir\"])\n"
      ],
      "metadata": {
        "id": "gv2stqF0xmdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 8 — Deletion statistics summary\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n=== DELETION SUMMARY ===\")\n",
        "base_before = baseline_info[\"total_candidate_labels_before_pruning\"]\n",
        "print(\"Baseline candidate labels:\", base_before)\n",
        "\n",
        "for tau in TAU_BUILD_LIST:\n",
        "    before  = PRUNED_INFOS[tau][\"total_candidate_labels_before_pruning\"]\n",
        "    deleted = PRUNED_INFOS[tau][\"total_deleted_label_instances\"]\n",
        "    uniq3d  = PRUNED_INFOS[tau][\"total_unique_3d_objects_seen\"]\n",
        "    print(f\"tau={tau:.1f}  before={before}  deleted={deleted}  remaining={before-deleted}  uniq3d={uniq3d}\")\n"
      ],
      "metadata": {
        "id": "xQh-7AQ6xmWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n"
      ],
      "metadata": {
        "id": "1v382SJcxmT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 12 — Multi-seed robustness (SAFE reruns) + best.pt eval\n",
        "# ============================================================\n",
        "\n",
        "SEEDS = [7, 17, 27]\n",
        "BASELINE_DIR = Path(baseline_info[\"dataset_dir\"])\n",
        "EVAL_DIR = BASELINE_DIR\n",
        "\n",
        "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE)\n",
        "\n",
        "if \"EPOCHS_FINAL\" not in globals():\n",
        "    EPOCHS_FINAL = 30\n",
        "EPOCHS = int(EPOCHS_FINAL)\n",
        "\n",
        "def get_run_save_dir(train_dir: Path, run_name: str) -> Path:\n",
        "    # Ultralytics default: {project}/{name}\n",
        "    return train_dir / \"runs_multiseed\" / run_name\n",
        "\n",
        "def best_weights_exist(train_dir: Path, run_name: str) -> Optional[Path]:\n",
        "    save_dir = get_run_save_dir(train_dir, run_name)\n",
        "    best_pt = save_dir / \"weights\" / \"best.pt\"\n",
        "    return best_pt if best_pt.exists() else None\n",
        "\n",
        "def train_and_eval_yolo(train_data_dir: Path, eval_data_dir: Path, run_name: str, seed: int):\n",
        "    train_data_dir = Path(train_data_dir)\n",
        "    eval_data_dir  = Path(eval_data_dir)\n",
        "\n",
        "    # ---- skip training if already done ----\n",
        "    existing_best = best_weights_exist(train_data_dir, run_name)\n",
        "    if (existing_best is not None) and (not FORCE_RETRAIN_MODELS):\n",
        "        model = YOLO(str(existing_best))\n",
        "        train_time_sec = np.nan\n",
        "        epochs_ran = np.nan\n",
        "        time_per_epoch_sec = np.nan\n",
        "        print(f\"✅ [SKIP TRAIN] Found best.pt for {run_name}\")\n",
        "    else:\n",
        "        model = YOLO(\"yolov8n.pt\")\n",
        "        t0 = time.time()\n",
        "        train_res = model.train(\n",
        "            data=str(train_data_dir / \"data.yaml\"),\n",
        "            epochs=EPOCHS,\n",
        "            imgsz=IMGSZ,\n",
        "            batch=BATCH,\n",
        "            device=DEVICE,\n",
        "            cache=True,\n",
        "            workers=4,\n",
        "            name=run_name,\n",
        "            project=str(train_data_dir / \"runs_multiseed\"),\n",
        "            verbose=False,\n",
        "            seed=seed,\n",
        "        )\n",
        "        t1 = time.time()\n",
        "        train_time_sec = t1 - t0\n",
        "\n",
        "        results_csv = Path(train_res.save_dir) / \"results.csv\"\n",
        "        if results_csv.exists():\n",
        "            df = pd.read_csv(results_csv)\n",
        "            epochs_ran = len(df)\n",
        "        else:\n",
        "            epochs_ran = EPOCHS\n",
        "        time_per_epoch_sec = train_time_sec / max(int(epochs_ran), 1)\n",
        "\n",
        "        # Use best weights for eval\n",
        "        best_pt = Path(train_res.save_dir) / \"weights\" / \"best.pt\"\n",
        "        if best_pt.exists():\n",
        "            model = YOLO(str(best_pt))\n",
        "\n",
        "    # ---- eval always on unpruned ----\n",
        "    t2 = time.time()\n",
        "    metrics = model.val(\n",
        "        data=str(eval_data_dir / \"data.yaml\"),\n",
        "        device=DEVICE,\n",
        "        verbose=False\n",
        "    )\n",
        "    t3 = time.time()\n",
        "    val_time_sec = t3 - t2\n",
        "\n",
        "    precision = float(metrics.box.mp)\n",
        "    recall    = float(metrics.box.mr)\n",
        "    map50     = float(metrics.box.map50)\n",
        "    map5095   = float(metrics.box.map)\n",
        "    f1        = 2 * precision * recall / (precision + recall + 1e-12)\n",
        "\n",
        "    return {\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": float(f1),\n",
        "        \"mAP50\": map50,\n",
        "        \"mAP50-95\": map5095,\n",
        "        \"train_time_sec\": float(train_time_sec) if train_time_sec==train_time_sec else np.nan,\n",
        "        \"val_time_sec\": float(val_time_sec),\n",
        "        \"epochs_ran\": int(epochs_ran) if epochs_ran==epochs_ran else np.nan,\n",
        "        \"time_per_epoch_sec\": float(time_per_epoch_sec) if time_per_epoch_sec==time_per_epoch_sec else np.nan,\n",
        "    }\n",
        "\n",
        "def stats_for_tau(tau_val):\n",
        "    if tau_val == \"unpruned\":\n",
        "        before  = baseline_info[\"total_candidate_labels_before_pruning\"]\n",
        "        deleted = baseline_info[\"total_deleted_label_instances\"]\n",
        "        uniq3d  = baseline_info.get(\"total_unique_3d_objects_seen\", np.nan)\n",
        "    else:\n",
        "        info = PRUNED_INFOS[float(tau_val)]\n",
        "        before  = info[\"total_candidate_labels_before_pruning\"]\n",
        "        deleted = info[\"total_deleted_label_instances\"]\n",
        "        uniq3d  = info.get(\"total_unique_3d_objects_seen\", np.nan)\n",
        "    return before, deleted, before - deleted, uniq3d\n",
        "\n",
        "rows = []\n",
        "\n",
        "# Baseline\n",
        "for seed in SEEDS:\n",
        "    run_name = f\"baseline__seed{seed}\"\n",
        "    m = train_and_eval_yolo(BASELINE_DIR, EVAL_DIR, run_name, seed)\n",
        "    before, deleted, remaining, uniq3d = stats_for_tau(\"unpruned\")\n",
        "    rows.append({\n",
        "        \"condition\": \"baseline\",\n",
        "        \"tau_BCS\": \"unpruned\",\n",
        "        \"seed\": seed,\n",
        "        \"candidate_labels_before\": before,\n",
        "        \"deleted_labels\": deleted,\n",
        "        \"remaining_labels\": remaining,\n",
        "        \"labels_removed_pct\": deleted / max(before,1),\n",
        "        \"unique_3d_objects_seen\": uniq3d,\n",
        "        **m\n",
        "    })\n",
        "\n",
        "# Pruned (reported taus only)\n",
        "for tau in TAUS_REPORTED:\n",
        "    train_dir = Path(PRUNED_INFOS[tau][\"dataset_dir\"])\n",
        "    for seed in SEEDS:\n",
        "        run_name = f\"bcs_tau{tau:.1f}__seed{seed}\"\n",
        "        m = train_and_eval_yolo(train_dir, EVAL_DIR, run_name, seed)\n",
        "        before, deleted, remaining, uniq3d = stats_for_tau(tau)\n",
        "        rows.append({\n",
        "            \"condition\": \"bcs\",\n",
        "            \"tau_BCS\": float(tau),\n",
        "            \"seed\": seed,\n",
        "            \"candidate_labels_before\": before,\n",
        "            \"deleted_labels\": deleted,\n",
        "            \"remaining_labels\": remaining,\n",
        "            \"labels_removed_pct\": deleted / max(before,1),\n",
        "            \"unique_3d_objects_seen\": uniq3d,\n",
        "            **m\n",
        "        })\n",
        "\n",
        "runs_df = pd.DataFrame(rows)\n",
        "raw_path = OUT_ROOT / \"yolo_multiseed_raw_runs.csv\"\n",
        "runs_df.to_csv(raw_path, index=False)\n",
        "print(\"\\nSaved raw runs to:\", raw_path)\n",
        "\n",
        "metric_cols = [\"mAP50\",\"mAP50-95\",\"Precision\",\"Recall\",\"F1-Score\"]\n",
        "perf_summary = runs_df.groupby([\"condition\",\"tau_BCS\"])[metric_cols].agg([\"mean\",\"std\"])\n",
        "perf_summary.columns = [f\"{m}_{s}\" for m,s in perf_summary.columns]\n",
        "perf_summary = perf_summary.reset_index().round(4)\n",
        "\n",
        "perf_path = OUT_ROOT / \"yolo_multiseed_summary_mean_std.csv\"\n",
        "perf_summary.to_csv(perf_path, index=False)\n",
        "\n",
        "print(\"\\n=== MULTI-SEED PERFORMANCE SUMMARY (mean ± std) ===\")\n",
        "print(perf_summary.to_string(index=False))\n",
        "print(\"\\nSaved:\", perf_path)\n"
      ],
      "metadata": {
        "id": "LDWq7gepyPQJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}