{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehri-satari/Data-Mining-Course-Project/blob/main/Untitled29.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoprK8FblxIr",
        "outputId": "c53cbb9f-0aef-4d33-81b6-5213abd66523"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMounted at /content/drive\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CELL 0 — Colab installs + imports + Drive mount\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install ultralytics opencv-python pillow tqdm\n",
        "!pip -q install av2\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import shutil\n",
        "import re\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, List, Optional, Any, Set\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from av2.utils import io as io_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 1 — Log IDs + find AV2 root (auto)\n",
        "# ============================================================\n",
        "\n",
        "LOG_IDS = [\n",
        "    \"0526e68e-2ff1-3e53-b0f8-45df02e45a93\",\n",
        "    \"04973bcf-fc64-367c-9642-6d6c5f363b61\",\n",
        "    \"03fba633-8085-30bc-b675-687a715536ac\",\n",
        "    \"03b2cf2d-fb61-36fe-936f-36bbf197a8ac\",\n",
        "    \"0322b098-7e42-34db-bcec-9a4d072191e9\",\n",
        "    \"022af476-9937-3e70-be52-f65420d52703\",\n",
        "    \"01bb304d-7bd8-35f8-bbef-7086b688e35e\",\n",
        "    \"00a6ffc1-6ce9-3bc3-a060-6006e9893a1a\",\n",
        "]\n",
        "\n",
        "def find_av2_root_by_log_ids(\n",
        "    log_ids,\n",
        "    search_roots=(Path(\"/content/drive/MyDrive\"), Path(\"/content/drive/Shareddrives\")),\n",
        "    max_matches_per_root=10\n",
        ") -> Path:\n",
        "    first = log_ids[0]\n",
        "    for root in search_roots:\n",
        "        if not root.exists():\n",
        "            continue\n",
        "        candidates = []\n",
        "        for p in root.rglob(first):\n",
        "            if p.is_dir():\n",
        "                candidates.append(p)\n",
        "                if len(candidates) >= max_matches_per_root:\n",
        "                    break\n",
        "\n",
        "        for log_dir in candidates:\n",
        "            av2_root = log_dir.parent\n",
        "            ok = True\n",
        "            for lid in log_ids:\n",
        "                lid_dir = av2_root / lid\n",
        "                if not lid_dir.is_dir():\n",
        "                    ok = False; break\n",
        "                if not (lid_dir / \"annotations.feather\").exists():\n",
        "                    ok = False; break\n",
        "                if not (lid_dir / \"calibration\" / \"intrinsics.feather\").exists():\n",
        "                    ok = False; break\n",
        "                if not (lid_dir / \"calibration\" / \"egovehicle_SE3_sensor.feather\").exists():\n",
        "                    ok = False; break\n",
        "            if ok:\n",
        "                return av2_root\n",
        "\n",
        "    raise FileNotFoundError(\"Could not locate AV2 root folder in Drive.\")\n",
        "\n",
        "AV2_ROOT = find_av2_root_by_log_ids(LOG_IDS)\n",
        "print(\"✅ Found AV2_ROOT:\", AV2_ROOT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YJzrwyXmBqW",
        "outputId": "6b4402f7-a84c-4c0a-e147-4b94a30243d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Found AV2_ROOT: /content/drive/MyDrive/Argoverse2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 2 — Global configuration\n",
        "# ============================================================\n",
        "\n",
        "# Output root\n",
        "OUT_ROOT = Path(\"/content/drive/MyDrive/av2_redundancy_yolo_multi_logs\")\n",
        "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Global train/val split seed (fixed across all runs)\n",
        "SPLIT_SEED = 7\n",
        "\n",
        "# Pairing tolerance\n",
        "MAX_TS_DIFF_NS = 50_000_000  # 50ms\n",
        "\n",
        "# Pruning taus built (can be broader)\n",
        "TAU_BUILD_LIST = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "\n",
        "# Reported taus for paper (run multi-seed only on these)\n",
        "# EDIT THIS to match your paper table (example uses 0.5 and 0.6)\n",
        "TAUS_REPORTED = [0.5, 0.6]\n",
        "\n",
        "# Baseline tau that guarantees \"no pruning\"\n",
        "BASELINE_TAU = 1e9\n",
        "\n",
        "# Training defaults (will be overwritten by EPOCHS_FINAL after diagnostic)\n",
        "IMGSZ = 640\n",
        "BATCH = 16\n",
        "\n",
        "print(\"OUT_ROOT:\", OUT_ROOT)\n",
        "print(\"TAU_BUILD_LIST:\", TAU_BUILD_LIST)\n",
        "print(\"TAUS_REPORTED:\", TAUS_REPORTED)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e00WytOmmFOJ",
        "outputId": "5e545097-b0d8-4719-c343-7fa57a282212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OUT_ROOT: /content/drive/MyDrive/av2_redundancy_yolo_multi_logs\n",
            "TAU_BUILD_LIST: [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
            "TAUS_REPORTED: [0.5, 0.6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 3 — Geometry utilities (same as your notebook)\n",
        "# ============================================================\n",
        "\n",
        "def quat_to_rotmat(qw, qx, qy, qz) -> np.ndarray:\n",
        "    q = np.array([qw, qx, qy, qz], dtype=np.float64)\n",
        "    q = q / (np.linalg.norm(q) + 1e-12)\n",
        "    w, x, y, z = q\n",
        "    R = np.array([\n",
        "        [1-2*(y*y+z*z), 2*(x*y - z*w), 2*(x*z + y*w)],\n",
        "        [2*(x*y + z*w), 1-2*(x*x+z*z), 2*(y*z - x*w)],\n",
        "        [2*(x*z - y*w), 2*(y*z + x*w), 1-2*(x*x+y*y)],\n",
        "    ], dtype=np.float64)\n",
        "    return R\n",
        "\n",
        "@dataclass\n",
        "class SE3:\n",
        "    R: np.ndarray\n",
        "    t: np.ndarray\n",
        "    def inverse(self) -> \"SE3\":\n",
        "        R_inv = self.R.T\n",
        "        t_inv = -R_inv @ self.t\n",
        "        return SE3(R=R_inv, t=t_inv)\n",
        "    def transform_points(self, pts: np.ndarray) -> np.ndarray:\n",
        "        return (pts @ self.R.T) + self.t.reshape(1, 3)\n",
        "\n",
        "@dataclass\n",
        "class CameraIntrinsics:\n",
        "    fx: float\n",
        "    fy: float\n",
        "    cx: float\n",
        "    cy: float\n",
        "\n",
        "def build_intrinsics_dict(intr_df: pd.DataFrame) -> Dict[str, CameraIntrinsics]:\n",
        "    req = [\"sensor_name\", \"fx_px\", \"fy_px\", \"cx_px\", \"cy_px\"]\n",
        "    for c in req:\n",
        "        if c not in intr_df.columns:\n",
        "            raise ValueError(f\"Missing intrinsics column: {c}\")\n",
        "    intr = {}\n",
        "    for _, r in intr_df.iterrows():\n",
        "        intr[str(r[\"sensor_name\"])] = CameraIntrinsics(\n",
        "            fx=float(r[\"fx_px\"]), fy=float(r[\"fy_px\"]),\n",
        "            cx=float(r[\"cx_px\"]), cy=float(r[\"cy_px\"])\n",
        "        )\n",
        "    return intr\n",
        "\n",
        "def build_extrinsics_dict(extr_df: pd.DataFrame) -> Dict[str, SE3]:\n",
        "    if \"sensor_name\" not in extr_df.columns:\n",
        "        raise ValueError(\"extrinsics missing 'sensor_name'\")\n",
        "    quat_cols = [c for c in [\"qw\", \"qx\", \"qy\", \"qz\"] if c in extr_df.columns]\n",
        "    trans_cols = [c for c in [\"tx_m\", \"ty_m\", \"tz_m\"] if c in extr_df.columns]\n",
        "    extr: Dict[str, SE3] = {}\n",
        "    for _, r in extr_df.iterrows():\n",
        "        name = str(r[\"sensor_name\"])\n",
        "        if len(quat_cols) == 4 and len(trans_cols) == 3:\n",
        "            R = quat_to_rotmat(float(r[\"qw\"]), float(r[\"qx\"]), float(r[\"qy\"]), float(r[\"qz\"]))\n",
        "            t = np.array([float(r[\"tx_m\"]), float(r[\"ty_m\"]), float(r[\"tz_m\"])], dtype=np.float64)\n",
        "            extr[name] = SE3(R=R, t=t)\n",
        "        else:\n",
        "            mat_col = None\n",
        "            for cand in [\"T_egovehicle_sensor\", \"egovehicle_SE3_sensor\", \"transform_matrix\"]:\n",
        "                if cand in extr_df.columns:\n",
        "                    mat_col = cand\n",
        "                    break\n",
        "            if mat_col is None:\n",
        "                raise ValueError(\"Extrinsics format not recognized.\")\n",
        "            T = np.array(r[mat_col], dtype=np.float64).reshape(4, 4)\n",
        "            extr[name] = SE3(R=T[:3, :3], t=T[:3, 3])\n",
        "    return extr\n",
        "\n",
        "def get_col(available_cols, candidates):\n",
        "    for c in candidates:\n",
        "        if c in available_cols:\n",
        "            return c\n",
        "    raise KeyError(f\"None of {candidates} found in columns.\")\n",
        "\n",
        "def cuboid_corners_ego(row: pd.Series) -> np.ndarray:\n",
        "    cols = set(row.index)\n",
        "    cx = float(row[get_col(cols, [\"center_x\", \"tx_m\", \"x\", \"translation_x\"])])\n",
        "    cy = float(row[get_col(cols, [\"center_y\", \"ty_m\", \"y\", \"translation_y\"])])\n",
        "    cz = float(row[get_col(cols, [\"center_z\", \"tz_m\", \"z\", \"translation_z\"])])\n",
        "    length = float(row[get_col(cols, [\"length_m\", \"length\"])])\n",
        "    width  = float(row[get_col(cols, [\"width_m\", \"width\"])])\n",
        "    height = float(row[get_col(cols, [\"height_m\", \"height\"])])\n",
        "    qw = float(row[get_col(cols, [\"qw\", \"rotation_qw\"])])\n",
        "    qx = float(row[get_col(cols, [\"qx\", \"rotation_qx\"])])\n",
        "    qy = float(row[get_col(cols, [\"qy\", \"rotation_qy\"])])\n",
        "    qz = float(row[get_col(cols, [\"qz\", \"rotation_qz\"])])\n",
        "    R = quat_to_rotmat(qw, qx, qy, qz)\n",
        "    center = np.array([cx, cy, cz], dtype=np.float64)\n",
        "\n",
        "    l2, w2, h2 = length/2, width/2, height/2\n",
        "    corners_local = np.array([\n",
        "        [ l2,  w2,  h2],[ l2, -w2,  h2],[-l2, -w2,  h2],[-l2,  w2,  h2],\n",
        "        [ l2,  w2, -h2],[ l2, -w2, -h2],[-l2, -w2, -h2],[-l2,  w2, -h2],\n",
        "    ], dtype=np.float64)\n",
        "    return (corners_local @ R.T) + center.reshape(1, 3)\n",
        "\n",
        "@dataclass\n",
        "class Box2D:\n",
        "    xmin: float\n",
        "    ymin: float\n",
        "    xmax: float\n",
        "    ymax: float\n",
        "    bcs: float\n",
        "\n",
        "def project_points_to_image(pts_cam: np.ndarray, intr: CameraIntrinsics) -> np.ndarray:\n",
        "    x, y, z = pts_cam[:,0], pts_cam[:,1], pts_cam[:,2]\n",
        "    eps = 1e-9\n",
        "    u = intr.fx*(x/(z+eps)) + intr.cx\n",
        "    v = intr.fy*(y/(z+eps)) + intr.cy\n",
        "    return np.stack([u,v,z], axis=1)\n",
        "\n",
        "def bbox_and_bcs_from_cuboid(corners_ego, intr, T_sensor_ego, img_w, img_h) -> Optional[Box2D]:\n",
        "    corners_cam = T_sensor_ego.transform_points(corners_ego)\n",
        "    if np.all(corners_cam[:,2] <= 0.1):\n",
        "        return None\n",
        "    uvz = project_points_to_image(corners_cam, intr)\n",
        "    u, v, z = uvz[:,0], uvz[:,1], uvz[:,2]\n",
        "    valid = z > 0.1\n",
        "    if valid.sum() < 2:\n",
        "        return None\n",
        "    u_full, v_full = u[valid], v[valid]\n",
        "    xmin_full, xmax_full = float(u_full.min()), float(u_full.max())\n",
        "    ymin_full, ymax_full = float(v_full.min()), float(v_full.max())\n",
        "    full_w, full_h = max(0.0, xmax_full-xmin_full), max(0.0, ymax_full-ymin_full)\n",
        "    area_full = full_w*full_h\n",
        "    if area_full <= 1e-6:\n",
        "        return None\n",
        "    xmin_clip = max(0.0, min(img_w-1.0, xmin_full))\n",
        "    xmax_clip = max(0.0, min(img_w-1.0, xmax_full))\n",
        "    ymin_clip = max(0.0, min(img_h-1.0, ymin_full))\n",
        "    ymax_clip = max(0.0, min(img_h-1.0, ymax_full))\n",
        "    clip_w, clip_h = max(0.0, xmax_clip-xmin_clip), max(0.0, ymax_clip-ymin_clip)\n",
        "    area_clip = clip_w*clip_h\n",
        "    bcs = float(area_clip/area_full)\n",
        "    if area_clip <= 1.0:\n",
        "        return None\n",
        "    return Box2D(xmin=xmin_clip, ymin=ymin_clip, xmax=xmax_clip, ymax=ymax_clip, bcs=bcs)\n",
        "\n",
        "def yolo_line_from_box(box: Box2D, cls_id: int, img_w: int, img_h: int) -> str:\n",
        "    cx = ((box.xmin+box.xmax)/2.0)/img_w\n",
        "    cy = ((box.ymin+box.ymax)/2.0)/img_h\n",
        "    w  = (box.xmax-box.xmin)/img_w\n",
        "    h  = (box.ymax-box.ymin)/img_h\n",
        "    cx = min(max(float(cx), 0.0), 1.0)\n",
        "    cy = min(max(float(cy), 0.0), 1.0)\n",
        "    w  = min(max(float(w),  0.0), 1.0)\n",
        "    h  = min(max(float(h),  0.0), 1.0)\n",
        "    return f\"{cls_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\"\n"
      ],
      "metadata": {
        "id": "uwqABg5NmQrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 4 — Camera image indexing + overlap pairs\n",
        "# ============================================================\n",
        "\n",
        "def find_camera_root(scene_path: Path) -> Path:\n",
        "    candidates = [\n",
        "        scene_path / \"sensors\" / \"cameras\",\n",
        "        scene_path / \"sensor\" / \"cameras\",\n",
        "        scene_path / \"cameras\",\n",
        "    ]\n",
        "    for p in candidates:\n",
        "        if p.exists():\n",
        "            return p\n",
        "    raise FileNotFoundError(f\"Cannot find camera root under {scene_path}\")\n",
        "\n",
        "def parse_timestamp_from_filename(p: Path) -> Optional[int]:\n",
        "    stem = p.stem\n",
        "    return int(stem) if stem.isdigit() else None\n",
        "\n",
        "def index_images(cam_root: Path, cameras: List[str]) -> Dict[str, Dict[int, Path]]:\n",
        "    idx = {}\n",
        "    for cam in cameras:\n",
        "        cam_dir = cam_root / cam\n",
        "        if not cam_dir.exists():\n",
        "            idx[cam] = {}; continue\n",
        "        ts_map = {}\n",
        "        for ext in [\"*.jpg\",\"*.jpeg\",\"*.png\"]:\n",
        "            for p in cam_dir.glob(ext):\n",
        "                ts = parse_timestamp_from_filename(p)\n",
        "                if ts is not None:\n",
        "                    ts_map[ts] = p\n",
        "        idx[cam] = ts_map\n",
        "    return idx\n",
        "\n",
        "def nearest_timestamp(target: int, available_sorted: List[int], max_diff_ns: int = 50_000_000) -> Optional[int]:\n",
        "    if not available_sorted:\n",
        "        return None\n",
        "    arr = np.array(available_sorted, dtype=np.int64)\n",
        "    i = int(np.searchsorted(arr, target))\n",
        "    cand = []\n",
        "    if i < len(arr): cand.append(int(arr[i]))\n",
        "    if i > 0: cand.append(int(arr[i-1]))\n",
        "    best = min(cand, key=lambda x: abs(int(x)-int(target)))\n",
        "    return int(best) if abs(int(best)-int(target)) <= max_diff_ns else None\n",
        "\n",
        "def wrap_pi(a: float) -> float:\n",
        "    return float((a + np.pi) % (2*np.pi) - np.pi)\n",
        "\n",
        "def fov_segments(center: float, hfov: float):\n",
        "    a1 = wrap_pi(center - hfov/2)\n",
        "    a2 = wrap_pi(center + hfov/2)\n",
        "    if a1 <= a2: return [(a1,a2)]\n",
        "    return [(a1,np.pi),(-np.pi,a2)]\n",
        "\n",
        "def seg_overlap(s1, s2) -> float:\n",
        "    left = max(s1[0], s2[0]); right = min(s1[1], s2[1])\n",
        "    return max(0.0, right-left)\n",
        "\n",
        "def circular_overlap(center1, hfov1, center2, hfov2) -> float:\n",
        "    segs1 = fov_segments(center1,hfov1)\n",
        "    segs2 = fov_segments(center2,hfov2)\n",
        "    ov = 0.0\n",
        "    for a in segs1:\n",
        "        for b in segs2:\n",
        "            ov += seg_overlap(a,b)\n",
        "    return float(min(ov, min(hfov1,hfov2)))\n",
        "\n",
        "def camera_yaw_center_in_ego(T_ego_sensor: SE3) -> float:\n",
        "    forward_cam = np.array([0.0,0.0,1.0], dtype=np.float64)\n",
        "    forward_ego = T_ego_sensor.R @ forward_cam\n",
        "    return float(np.arctan2(forward_ego[1], forward_ego[0]))\n",
        "\n",
        "def hfov_from_intrinsics(intr: CameraIntrinsics, img_w: int) -> float:\n",
        "    return float(2.0*np.arctan(img_w/(2.0*intr.fx)))\n",
        "\n",
        "def compute_overlap_pairs(cameras, INTR, T_EGO_SENSOR, IMG_INDEX, min_overlap_deg=5.0):\n",
        "    min_overlap = math.radians(min_overlap_deg)\n",
        "    cam_sizes = {}\n",
        "    for cam in cameras:\n",
        "        ts_map = IMG_INDEX.get(cam, {})\n",
        "        if not ts_map: continue\n",
        "        any_path = next(iter(ts_map.values()))\n",
        "        with Image.open(any_path) as im:\n",
        "            cam_sizes[cam] = im.size\n",
        "\n",
        "    cam_info = {}\n",
        "    for cam in cameras:\n",
        "        if cam not in cam_sizes or cam not in INTR or cam not in T_EGO_SENSOR: continue\n",
        "        W,_ = cam_sizes[cam]\n",
        "        yaw = camera_yaw_center_in_ego(T_EGO_SENSOR[cam])\n",
        "        hfov = hfov_from_intrinsics(INTR[cam], W)\n",
        "        cam_info[cam] = (yaw,hfov)\n",
        "\n",
        "    cams = list(cam_info.keys())\n",
        "    pairs = []\n",
        "    for i in range(len(cams)):\n",
        "        for j in range(i+1,len(cams)):\n",
        "            c1,c2 = cams[i], cams[j]\n",
        "            yaw1,hfov1 = cam_info[c1]\n",
        "            yaw2,hfov2 = cam_info[c2]\n",
        "            ov = circular_overlap(yaw1,hfov1,yaw2,hfov2)\n",
        "            if ov >= min_overlap:\n",
        "                pairs.append((c1,c2,ov))\n",
        "    pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "    return pairs\n"
      ],
      "metadata": {
        "id": "uOJfaCjsmW3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 5 — Load metadata for ALL logs + GLOBAL class map\n",
        "# ============================================================\n",
        "\n",
        "def load_initial_data(scene_path: Path):\n",
        "    ann_df  = io_utils.read_feather(scene_path / \"annotations.feather\")\n",
        "    intr_df = io_utils.read_feather(scene_path / \"calibration\" / \"intrinsics.feather\")\n",
        "    extr_df = io_utils.read_feather(scene_path / \"calibration\" / \"egovehicle_SE3_sensor.feather\")\n",
        "    return ann_df, intr_df, extr_df\n",
        "\n",
        "ANN_BY_LOG: Dict[str, pd.DataFrame] = {}\n",
        "all_categories: Set[str] = set()\n",
        "\n",
        "CATEGORY_COL = \"category\"\n",
        "\n",
        "for log_id in LOG_IDS:\n",
        "    scene_path = AV2_ROOT / log_id\n",
        "    ann_df, _, _ = load_initial_data(scene_path)\n",
        "    ANN_BY_LOG[log_id] = ann_df\n",
        "\n",
        "    if CATEGORY_COL not in ann_df.columns:\n",
        "        raise ValueError(f\"{log_id}: missing '{CATEGORY_COL}'\")\n",
        "\n",
        "    cats = ann_df[CATEGORY_COL].dropna().astype(str).unique().tolist()\n",
        "    all_categories.update(cats)\n",
        "\n",
        "NAMES = sorted(list(all_categories))\n",
        "CLASS_MAP = {c: i for i, c in enumerate(NAMES)}\n",
        "\n",
        "print(\"GLOBAL Num classes:\", len(NAMES))\n",
        "print(\"Example class map:\", list(CLASS_MAP.items())[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-KY09xJmW0H",
        "outputId": "7b988c56-9856-4933-b554-0ee2787cf88a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL Num classes: 19\n",
            "Example class map: [('BICYCLE', 0), ('BOLLARD', 1), ('BOX_TRUCK', 2), ('BUS', 3), ('CONSTRUCTION_BARREL', 4), ('CONSTRUCTION_CONE', 5), ('LARGE_VEHICLE', 6), ('MOTORCYCLE', 7), ('MOTORCYCLIST', 8), ('PEDESTRIAN', 9)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 6 — Shared train/val split across ALL logs\n",
        "# ============================================================\n",
        "\n",
        "def make_train_val_split_by_log_timestamp(ann_by_log, train_ratio=0.8, seed=7):\n",
        "    keys = []\n",
        "    for log_id, ann_df in ann_by_log.items():\n",
        "        if \"timestamp_ns\" not in ann_df.columns:\n",
        "            raise ValueError(f\"{log_id}: missing timestamp_ns\")\n",
        "        for ts in ann_df[\"timestamp_ns\"].dropna().astype(np.int64).unique():\n",
        "            keys.append((log_id, int(ts)))\n",
        "    rng = np.random.RandomState(seed)\n",
        "    rng.shuffle(keys)\n",
        "    n_train = int(len(keys)*train_ratio)\n",
        "    return set(keys[:n_train]), set(keys[n_train:])\n",
        "\n",
        "TRAIN_KEYS, VAL_KEYS = make_train_val_split_by_log_timestamp(ANN_BY_LOG, 0.8, SPLIT_SEED)\n",
        "print(\"Train keys:\", len(TRAIN_KEYS), \"| Val keys:\", len(VAL_KEYS))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkCcs4WRmmGL",
        "outputId": "8683963e-6d45-445e-ea97-437f6a224855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train keys: 1002 | Val keys: 251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 7 — Build YOLO dataset for ALL logs (baseline + pruned taus)\n",
        "# ============================================================\n",
        "\n",
        "def reset_dir(p: Path):\n",
        "    if p.exists():\n",
        "        shutil.rmtree(p)\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def build_yolo_from_av2_logs(\n",
        "    log_ids, av2_root, ann_by_log, out_root, tau_bcs,\n",
        "    train_keys, val_keys, class_map, names,\n",
        "    max_ts_diff_ns=50_000_000, drop_empty_images=False\n",
        "):\n",
        "    dataset_dir = Path(out_root)\n",
        "    reset_dir(dataset_dir)\n",
        "    for split in [\"train\",\"val\"]:\n",
        "        (dataset_dir/\"images\"/split).mkdir(parents=True, exist_ok=True)\n",
        "        (dataset_dir/\"labels\"/split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    total_candidate_labels = 0\n",
        "    total_deleted_labels = 0\n",
        "    total_unique_3d_objects = set()\n",
        "\n",
        "    for log_id in log_ids:\n",
        "        scene_path = av2_root / log_id\n",
        "        ann_df = ann_by_log[log_id]\n",
        "\n",
        "        _, intr_df, extr_df = load_initial_data(scene_path)\n",
        "        INTR = build_intrinsics_dict(intr_df)\n",
        "        T_EGO_SENSOR = build_extrinsics_dict(extr_df)            # sensor -> ego\n",
        "        T_SENSOR_EGO = {k: v.inverse() for k,v in T_EGO_SENSOR.items()}  # ego -> sensor\n",
        "\n",
        "        CAMERAS = intr_df[\"sensor_name\"].astype(str).unique().tolist()\n",
        "        CAM_ROOT = find_camera_root(scene_path)\n",
        "        IMG_INDEX = index_images(CAM_ROOT, CAMERAS)\n",
        "        OVERLAP_PAIRS = compute_overlap_pairs(CAMERAS, INTR, T_EGO_SENSOR, IMG_INDEX, min_overlap_deg=5.0)\n",
        "\n",
        "        cameras = [c for c in INTR.keys() if c in IMG_INDEX and len(IMG_INDEX[c])>0]\n",
        "        if not cameras:\n",
        "            print(f\"[WARN] {log_id}: no cameras with images. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        cam_size = {}\n",
        "        for cam in cameras:\n",
        "            any_path = next(iter(IMG_INDEX[cam].values()))\n",
        "            with Image.open(any_path) as im:\n",
        "                cam_size[cam] = im.size\n",
        "        cam_ts_sorted = {cam: sorted(IMG_INDEX[cam].keys()) for cam in cameras}\n",
        "\n",
        "        keys_for_log = sorted(list({k for k in (train_keys|val_keys) if k[0]==log_id}), key=lambda x: x[1])\n",
        "\n",
        "        for (_, ts) in tqdm(keys_for_log, desc=f\"Build {log_id[:8]} tau={tau_bcs}\", leave=False):\n",
        "            split = \"train\" if (log_id, ts) in train_keys else (\"val\" if (log_id, ts) in val_keys else None)\n",
        "            if split is None:\n",
        "                continue\n",
        "\n",
        "            ann_rows = ann_df[ann_df[\"timestamp_ns\"] == ts]\n",
        "            if ann_rows.empty:\n",
        "                continue\n",
        "\n",
        "            per_cam_boxes = {cam:{} for cam in cameras}  # cam -> track -> (box,cls,ts_img,img_path,W,H)\n",
        "\n",
        "            for _, row in ann_rows.iterrows():\n",
        "                track = str(row[\"track_uuid\"])\n",
        "                cat = row[CATEGORY_COL]\n",
        "                if pd.isna(cat):\n",
        "                    continue\n",
        "                cat_str = str(cat)\n",
        "                if cat_str not in class_map:\n",
        "                    continue\n",
        "                cls_id = int(class_map[cat_str])\n",
        "\n",
        "                corners = cuboid_corners_ego(row)\n",
        "\n",
        "                any_projection = False\n",
        "                for cam in cameras:\n",
        "                    ts_img = nearest_timestamp(ts, cam_ts_sorted[cam], max_diff_ns=max_ts_diff_ns)\n",
        "                    if ts_img is None:\n",
        "                        continue\n",
        "                    img_path = IMG_INDEX[cam][ts_img]\n",
        "                    W,H = cam_size[cam]\n",
        "\n",
        "                    box = bbox_and_bcs_from_cuboid(\n",
        "                        corners_ego=corners,\n",
        "                        intr=INTR[cam],\n",
        "                        T_sensor_ego=T_SENSOR_EGO[cam],  # ego -> camera\n",
        "                        img_w=W, img_h=H\n",
        "                    )\n",
        "                    if box is None:\n",
        "                        continue\n",
        "\n",
        "                    per_cam_boxes[cam][track] = (box, cls_id, ts_img, img_path, W, H)\n",
        "                    any_projection = True\n",
        "\n",
        "                if any_projection:\n",
        "                    total_unique_3d_objects.add((log_id, int(ts), track))\n",
        "\n",
        "            candidates_this_ts = sum(len(per_cam_boxes[cam]) for cam in cameras)\n",
        "            total_candidate_labels += candidates_this_ts\n",
        "\n",
        "            to_drop = set()\n",
        "            for camA, camB, _ in OVERLAP_PAIRS:\n",
        "                if camA not in per_cam_boxes or camB not in per_cam_boxes:\n",
        "                    continue\n",
        "                common_tracks = set(per_cam_boxes[camA].keys()) & set(per_cam_boxes[camB].keys())\n",
        "                for track in common_tracks:\n",
        "                    boxA, clsA, tsA, _, _, _ = per_cam_boxes[camA][track]\n",
        "                    boxB, clsB, tsB, _, _, _ = per_cam_boxes[camB][track]\n",
        "                    if clsA != clsB:\n",
        "                        continue\n",
        "                    if abs(boxA.bcs - boxB.bcs) > tau_bcs:\n",
        "                        if boxA.bcs >= boxB.bcs:\n",
        "                            to_drop.add((camB, track, tsB))\n",
        "                        else:\n",
        "                            to_drop.add((camA, track, tsA))\n",
        "\n",
        "            total_deleted_labels += len(to_drop)\n",
        "\n",
        "            for cam in cameras:\n",
        "                entries = list(per_cam_boxes[cam].items())\n",
        "                if not entries:\n",
        "                    continue\n",
        "                _, (_, _, ts_img, img_path, W, H) = entries[0]\n",
        "                out_img_name = f\"{log_id}_{cam}_{ts_img}.jpg\"\n",
        "                out_lbl_name = f\"{log_id}_{cam}_{ts_img}.txt\"\n",
        "\n",
        "                lines = []\n",
        "                for track, (box, cls_id, ts_img2, _, W2, H2) in per_cam_boxes[cam].items():\n",
        "                    if (cam, track, ts_img2) in to_drop:\n",
        "                        continue\n",
        "                    lines.append(yolo_line_from_box(box, cls_id, W2, H2))\n",
        "\n",
        "                if drop_empty_images and len(lines)==0:\n",
        "                    continue\n",
        "\n",
        "                shutil.copy(img_path, dataset_dir/\"images\"/split/out_img_name)\n",
        "                with open(dataset_dir/\"labels\"/split/out_lbl_name, \"w\") as f:\n",
        "                    f.write(\"\\n\".join(lines))\n",
        "\n",
        "    data_yaml = dataset_dir / \"data.yaml\"\n",
        "    yaml_text = (\n",
        "        f\"path: {dataset_dir}\\n\"\n",
        "        f\"train: images/train\\n\"\n",
        "        f\"val: images/val\\n\"\n",
        "        f\"nc: {len(names)}\\n\"\n",
        "        f\"names: {json.dumps(names)}\\n\"\n",
        "    )\n",
        "    with open(data_yaml, \"w\") as f:\n",
        "        f.write(yaml_text)\n",
        "\n",
        "    return {\n",
        "        \"dataset_dir\": dataset_dir,\n",
        "        \"data_yaml\": data_yaml,\n",
        "        \"total_candidate_labels_before_pruning\": int(total_candidate_labels),\n",
        "        \"total_deleted_label_instances\": int(total_deleted_labels),\n",
        "        \"total_unique_3d_objects_seen\": int(len(total_unique_3d_objects)),\n",
        "    }\n",
        "\n",
        "# Build baseline\n",
        "baseline_info = build_yolo_from_av2_logs(\n",
        "    log_ids=LOG_IDS,\n",
        "    av2_root=AV2_ROOT,\n",
        "    ann_by_log=ANN_BY_LOG,\n",
        "    out_root=OUT_ROOT / \"baseline_unpruned\",\n",
        "    tau_bcs=BASELINE_TAU,\n",
        "    train_keys=TRAIN_KEYS,\n",
        "    val_keys=VAL_KEYS,\n",
        "    class_map=CLASS_MAP,\n",
        "    names=NAMES,\n",
        "    max_ts_diff_ns=MAX_TS_DIFF_NS,\n",
        "    drop_empty_images=False,\n",
        ")\n",
        "\n",
        "print(\"✅ Baseline built:\", baseline_info)\n",
        "\n",
        "# Build pruned datasets\n",
        "PRUNED_INFOS = {}\n",
        "for tau in TAU_BUILD_LIST:\n",
        "    info = build_yolo_from_av2_logs(\n",
        "        log_ids=LOG_IDS,\n",
        "        av2_root=AV2_ROOT,\n",
        "        ann_by_log=ANN_BY_LOG,\n",
        "        out_root=OUT_ROOT / f\"pruned_tau{tau:.1f}\",\n",
        "        tau_bcs=float(tau),\n",
        "        train_keys=TRAIN_KEYS,\n",
        "        val_keys=VAL_KEYS,\n",
        "        class_map=CLASS_MAP,\n",
        "        names=NAMES,\n",
        "        max_ts_diff_ns=MAX_TS_DIFF_NS,\n",
        "        drop_empty_images=False,\n",
        "    )\n",
        "    PRUNED_INFOS[tau] = info\n",
        "    print(f\"✅ Pruned tau={tau:.1f} built:\", info[\"dataset_dir\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4Q5-2U5mqcU",
        "outputId": "97c52e43-67ad-454e-9fcc-0405ea88cf6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Build 03fba633 tau=1000000000.0:  43%|████▎     | 67/157 [02:50<03:34,  2.38s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 8 — Deletion statistics summary\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n=== DELETION SUMMARY ===\")\n",
        "base_before = baseline_info[\"total_candidate_labels_before_pruning\"]\n",
        "print(\"Baseline candidate labels:\", base_before)\n",
        "\n",
        "for tau in TAU_BUILD_LIST:\n",
        "    before  = PRUNED_INFOS[tau][\"total_candidate_labels_before_pruning\"]\n",
        "    deleted = PRUNED_INFOS[tau][\"total_deleted_label_instances\"]\n",
        "    uniq3d  = PRUNED_INFOS[tau][\"total_unique_3d_objects_seen\"]\n",
        "    print(f\"tau={tau:.1f}  before={before}  deleted={deleted}  remaining={before-deleted}  uniq3d={uniq3d}\")\n"
      ],
      "metadata": {
        "id": "DoqWeCwXmqZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 9 — Distribution shift analysis (baseline vs reported taus)\n",
        "# ============================================================\n",
        "\n",
        "def parse_yolo_labels(labels_dir: Path) -> pd.DataFrame:\n",
        "    rows = []\n",
        "    for p in labels_dir.glob(\"*.txt\"):\n",
        "        m = re.match(r\"(.+?)_(.+?)_(\\d+)\\.txt$\", p.name)\n",
        "        cam = m.group(2) if m else \"UNKNOWN\"\n",
        "        with open(p, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) != 5:\n",
        "                    continue\n",
        "                cls = int(parts[0])\n",
        "                _, _, w, h = map(float, parts[1:])\n",
        "                area = w * h\n",
        "                rows.append({\"cam\": cam, \"cls\": cls, \"area\": area})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def dist_shift_summary(dataset_dir: Path, split=\"train\"):\n",
        "    df = parse_yolo_labels(Path(dataset_dir) / \"labels\" / split)\n",
        "    if df.empty:\n",
        "        return df, {}, pd.Series(dtype=float), pd.Series(dtype=float)\n",
        "\n",
        "    area_stats = {\n",
        "        \"n_labels\": int(len(df)),\n",
        "        \"area_mean\": float(df[\"area\"].mean()),\n",
        "        \"area_median\": float(df[\"area\"].median()),\n",
        "        \"area_p10\": float(np.quantile(df[\"area\"], 0.10)),\n",
        "        \"area_p90\": float(np.quantile(df[\"area\"], 0.90)),\n",
        "    }\n",
        "    cls_pct = (df[\"cls\"].value_counts(normalize=True)).sort_index()\n",
        "    cam_pct = (df[\"cam\"].value_counts(normalize=True))\n",
        "    return df, area_stats, cls_pct, cam_pct\n",
        "\n",
        "baseline_dir = Path(baseline_info[\"dataset_dir\"])\n",
        "\n",
        "base_df, base_area, base_cls_pct, base_cam_pct = dist_shift_summary(baseline_dir, \"train\")\n",
        "print(\"Baseline area stats:\", base_area)\n",
        "\n",
        "shift_rows = []\n",
        "\n",
        "for tau in TAUS_REPORTED:\n",
        "    pruned_dir = Path(PRUNED_INFOS[tau][\"dataset_dir\"])\n",
        "    pr_df, pr_area, pr_cls_pct, pr_cam_pct = dist_shift_summary(pruned_dir, \"train\")\n",
        "    print(f\"\\nPruned tau={tau} area stats:\", pr_area)\n",
        "\n",
        "    # Top shifts (class and camera)\n",
        "    cls_compare = pd.concat(\n",
        "        [base_cls_pct.rename(\"baseline_pct\"), pr_cls_pct.rename(\"pruned_pct\")],\n",
        "        axis=1\n",
        "    ).fillna(0.0)\n",
        "    cls_compare[\"abs_diff_pct\"] = (cls_compare[\"pruned_pct\"] - cls_compare[\"baseline_pct\"]).abs()\n",
        "\n",
        "    cam_compare = pd.concat(\n",
        "        [base_cam_pct.rename(\"baseline_pct\"), pr_cam_pct.rename(\"pruned_pct\")],\n",
        "        axis=1\n",
        "    ).fillna(0.0)\n",
        "    cam_compare[\"abs_diff_pct\"] = (cam_compare[\"pruned_pct\"] - cam_compare[\"baseline_pct\"]).abs()\n",
        "\n",
        "    print(\"Top class pct shifts:\")\n",
        "    print(cls_compare.sort_values(\"abs_diff_pct\", ascending=False).head(10))\n",
        "\n",
        "    print(\"Top camera pct shifts:\")\n",
        "    print(cam_compare.sort_values(\"abs_diff_pct\", ascending=False).head(10))\n",
        "\n",
        "    shift_rows.append({\n",
        "        \"tau\": tau,\n",
        "        **{f\"baseline_{k}\": v for k,v in base_area.items()},\n",
        "        **{f\"pruned_{k}\": v for k,v in pr_area.items()},\n",
        "    })\n",
        "\n",
        "shift_df = pd.DataFrame(shift_rows)\n",
        "shift_path = OUT_ROOT / \"distribution_shift_area_stats.csv\"\n",
        "shift_df.to_csv(shift_path, index=False)\n",
        "print(\"\\nSaved distribution shift area stats to:\", shift_path)\n"
      ],
      "metadata": {
        "id": "OF0A9EsYmqWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 10 — Diagnostic early stopping on baseline to choose EPOCHS_FINAL\n",
        "# ============================================================\n",
        "\n",
        "BASELINE_DIR = Path(baseline_info[\"dataset_dir\"])\n",
        "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", DEVICE)\n",
        "\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "train_res = model.train(\n",
        "    data=str(BASELINE_DIR / \"data.yaml\"),\n",
        "    epochs=100,\n",
        "    patience=10,\n",
        "    imgsz=IMGSZ,\n",
        "    batch=BATCH,\n",
        "    device=DEVICE,\n",
        "    cache=True,\n",
        "    workers=4,\n",
        "    name=\"baseline_diagnostic_es\",\n",
        "    project=str(BASELINE_DIR / \"runs_diagnostic\"),\n",
        "    seed=7,\n",
        "    verbose=False,\n",
        ")\n",
        "print(\"Diagnostic run dir:\", train_res.save_dir)\n"
      ],
      "metadata": {
        "id": "0S8GjWrknBtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 11 — Set EPOCHS_FINAL from diagnostic run\n",
        "# ============================================================\n",
        "\n",
        "run_dir = Path(train_res.save_dir)\n",
        "df = pd.read_csv(run_dir / \"results.csv\")\n",
        "\n",
        "map_cols = [c for c in df.columns if (\"metrics/mAP50-95\" in c) or (\"metrics/mAP_0.5:0.95\" in c)]\n",
        "if not map_cols:\n",
        "    raise ValueError(f\"Could not find val mAP50-95 column. Available:\\n{df.columns.tolist()}\")\n",
        "\n",
        "map5095_col = map_cols[0]\n",
        "best_epoch_1based = int(df[map5095_col].idxmax()) + 1\n",
        "last_epoch_1based = len(df)\n",
        "\n",
        "print(\"val mAP50-95 column:\", map5095_col)\n",
        "print(\"Best epoch (1-based):\", best_epoch_1based)\n",
        "print(\"Last epoch trained (1-based):\", last_epoch_1based)\n",
        "\n",
        "# Conservative epoch budget for multi-seed\n",
        "EPOCHS_FINAL = min(last_epoch_1based + 5, 100) if last_epoch_1based < 100 else 100\n",
        "print(\"✅ Suggested EPOCHS_FINAL:\", EPOCHS_FINAL)\n"
      ],
      "metadata": {
        "id": "2-KbYdlFnBgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# CELL 12 — Multi-seed robustness + efficiency reporting\n",
        "# ============================================================\n",
        "\n",
        "SEEDS = [7, 17, 27]  # >= 3 seeds\n",
        "EPOCHS = int(EPOCHS_FINAL)\n",
        "\n",
        "BASELINE_DIR = Path(baseline_info[\"dataset_dir\"])\n",
        "EVAL_DIR = BASELINE_DIR\n",
        "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(\"DEVICE:\", DEVICE, \"| EPOCHS:\", EPOCHS, \"| SEEDS:\", SEEDS)\n",
        "print(\"Reported taus:\", TAUS_REPORTED)\n",
        "\n",
        "def stats_for_tau(tau_val):\n",
        "    if tau_val == \"unpruned\":\n",
        "        before  = baseline_info[\"total_candidate_labels_before_pruning\"]\n",
        "        deleted = baseline_info[\"total_deleted_label_instances\"]\n",
        "        uniq3d  = baseline_info[\"total_unique_3d_objects_seen\"]\n",
        "    else:\n",
        "        info = PRUNED_INFOS[float(tau_val)]\n",
        "        before  = info[\"total_candidate_labels_before_pruning\"]\n",
        "        deleted = info[\"total_deleted_label_instances\"]\n",
        "        uniq3d  = info[\"total_unique_3d_objects_seen\"]\n",
        "    return before, deleted, before - deleted, uniq3d\n",
        "\n",
        "def train_and_eval_yolo(train_data_dir, eval_data_dir, run_name, seed):\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    train_res = model.train(\n",
        "        data=str(Path(train_data_dir) / \"data.yaml\"),\n",
        "        epochs=EPOCHS,\n",
        "        imgsz=IMGSZ,\n",
        "        batch=BATCH,\n",
        "        device=DEVICE,\n",
        "        cache=True,\n",
        "        workers=4,\n",
        "        name=run_name,\n",
        "        project=str(Path(train_data_dir) / \"runs_multiseed\"),\n",
        "        verbose=False,\n",
        "        seed=seed,\n",
        "    )\n",
        "    t1 = time.time()\n",
        "\n",
        "    t2 = time.time()\n",
        "    metrics = model.val(\n",
        "        data=str(Path(eval_data_dir) / \"data.yaml\"),\n",
        "        device=DEVICE,\n",
        "        verbose=False\n",
        "    )\n",
        "    t3 = time.time()\n",
        "\n",
        "    precision = float(metrics.box.mp)\n",
        "    recall    = float(metrics.box.mr)\n",
        "    map50     = float(metrics.box.map50)\n",
        "    map5095   = float(metrics.box.map)\n",
        "    f1        = 2 * precision * recall / (precision + recall + 1e-12)\n",
        "\n",
        "    train_time_sec = t1 - t0\n",
        "    val_time_sec   = t3 - t2\n",
        "\n",
        "    # epochs actually ran (useful if any early stop happens)\n",
        "    epochs_ran = EPOCHS\n",
        "    results_csv = Path(train_res.save_dir) / \"results.csv\"\n",
        "    if results_csv.exists():\n",
        "        df = pd.read_csv(results_csv)\n",
        "        epochs_ran = len(df)\n",
        "\n",
        "    time_per_epoch_sec = train_time_sec / max(epochs_ran, 1)\n",
        "\n",
        "    return {\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": float(f1),\n",
        "        \"mAP50\": map50,\n",
        "        \"mAP50-95\": map5095,\n",
        "        \"train_time_sec\": float(train_time_sec),\n",
        "        \"val_time_sec\": float(val_time_sec),\n",
        "        \"epochs_ran\": int(epochs_ran),\n",
        "        \"time_per_epoch_sec\": float(time_per_epoch_sec),\n",
        "    }\n",
        "\n",
        "rows = []\n",
        "\n",
        "# Baseline\n",
        "for seed in SEEDS:\n",
        "    m = train_and_eval_yolo(BASELINE_DIR, EVAL_DIR, f\"baseline__seed{seed}\", seed)\n",
        "    before, deleted, remaining, uniq3d = stats_for_tau(\"unpruned\")\n",
        "    rows.append({\n",
        "        \"tau_BCS\": \"unpruned\",\n",
        "        \"seed\": seed,\n",
        "        \"candidate_labels_before\": before,\n",
        "        \"deleted_labels\": deleted,\n",
        "        \"remaining_labels\": remaining,\n",
        "        \"labels_removed_pct\": deleted / before,\n",
        "        \"unique_3d_objects_seen\": uniq3d,\n",
        "        **m\n",
        "    })\n",
        "    print(f\"Done baseline seed={seed}: mAP50={m['mAP50']:.4f}, mAP50-95={m['mAP50-95']:.4f}\")\n",
        "\n",
        "# Pruned (reported taus only)\n",
        "for tau in TAUS_REPORTED:\n",
        "    train_dir = Path(PRUNED_INFOS[tau][\"dataset_dir\"])\n",
        "    for seed in SEEDS:\n",
        "        m = train_and_eval_yolo(train_dir, EVAL_DIR, f\"tau{tau:.1f}__seed{seed}\", seed)\n",
        "        before, deleted, remaining, uniq3d = stats_for_tau(tau)\n",
        "        rows.append({\n",
        "            \"tau_BCS\": float(tau),\n",
        "            \"seed\": seed,\n",
        "            \"candidate_labels_before\": before,\n",
        "            \"deleted_labels\": deleted,\n",
        "            \"remaining_labels\": remaining,\n",
        "            \"labels_removed_pct\": deleted / before,\n",
        "            \"unique_3d_objects_seen\": uniq3d,\n",
        "            **m\n",
        "        })\n",
        "        print(f\"Done tau={tau:.1f} seed={seed}: mAP50={m['mAP50']:.4f}, mAP50-95={m['mAP50-95']:.4f}\")\n",
        "\n",
        "runs_df = pd.DataFrame(rows)\n",
        "raw_path = OUT_ROOT / \"yolo_multiseed_raw_runs.csv\"\n",
        "runs_df.to_csv(raw_path, index=False)\n",
        "print(\"\\nSaved raw runs to:\", raw_path)\n",
        "\n",
        "# Performance summary mean ± std (reviewer table)\n",
        "metric_cols = [\"mAP50\", \"mAP50-95\", \"Precision\", \"Recall\", \"F1-Score\"]\n",
        "perf_summary = (\n",
        "    runs_df.groupby(\"tau_BCS\")[metric_cols]\n",
        "           .agg([\"mean\",\"std\"])\n",
        ")\n",
        "perf_summary.columns = [f\"{m}_{s}\" for m,s in perf_summary.columns]\n",
        "perf_summary = perf_summary.reset_index()\n",
        "for c in perf_summary.columns:\n",
        "    if c != \"tau_BCS\":\n",
        "        perf_summary[c] = perf_summary[c].astype(float).round(4)\n",
        "\n",
        "perf_path = OUT_ROOT / \"yolo_multiseed_summary_mean_std.csv\"\n",
        "perf_summary.to_csv(perf_path, index=False)\n",
        "print(\"\\n=== MULTI-SEED PERFORMANCE SUMMARY (mean ± std) ===\")\n",
        "print(perf_summary.to_string(index=False))\n",
        "print(\"\\nSaved performance summary to:\", perf_path)\n",
        "\n",
        "# Efficiency summary mean ± std\n",
        "eff_cols = [\"labels_removed_pct\", \"time_per_epoch_sec\", \"train_time_sec\"]\n",
        "eff_summary = (\n",
        "    runs_df.groupby(\"tau_BCS\")[eff_cols]\n",
        "           .agg([\"mean\",\"std\"])\n",
        ")\n",
        "eff_summary.columns = [f\"{m}_{s}\" for m,s in eff_summary.columns]\n",
        "eff_summary = eff_summary.reset_index()\n",
        "for c in eff_summary.columns:\n",
        "    if c != \"tau_BCS\":\n",
        "        eff_summary[c] = eff_summary[c].astype(float).round(4)\n",
        "\n",
        "eff_path = OUT_ROOT / \"yolo_efficiency_summary_mean_std.csv\"\n",
        "eff_summary.to_csv(eff_path, index=False)\n",
        "print(\"\\n=== EFFICIENCY SUMMARY (mean ± std) ===\")\n",
        "print(eff_summary.to_string(index=False))\n",
        "print(\"\\nSaved efficiency summary to:\", eff_path)\n",
        "\n",
        "MULTISEED_RUNS_DF = runs_df\n",
        "MULTISEED_PERF_SUMMARY_DF = perf_summary\n",
        "MULTISEED_EFF_SUMMARY_DF = eff_summary\n"
      ],
      "metadata": {
        "id": "XdTx6DQcnBfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Efficiency gains: speedup vs baseline (reviewer table)\n",
        "# ============================================================\n",
        "\n",
        "# Baseline reference (mean across seeds)\n",
        "baseline_ref = (\n",
        "    runs_df[runs_df[\"tau_BCS\"] == \"unpruned\"]\n",
        "    .agg({\"time_per_epoch_sec\": \"mean\", \"train_time_sec\": \"mean\"})\n",
        ")\n",
        "base_tpe = float(baseline_ref[\"time_per_epoch_sec\"])\n",
        "base_ttrain = float(baseline_ref[\"train_time_sec\"])\n",
        "\n",
        "# Add per-run speedups\n",
        "runs_df[\"speedup_time_per_epoch\"] = base_tpe / runs_df[\"time_per_epoch_sec\"]\n",
        "runs_df[\"speedup_total_train_time\"] = base_ttrain / runs_df[\"train_time_sec\"]\n",
        "\n",
        "# Efficiency summary mean ± std (includes speedups)\n",
        "eff_cols = [\n",
        "    \"labels_removed_pct\",\n",
        "    \"time_per_epoch_sec\",\n",
        "    \"train_time_sec\",\n",
        "    \"speedup_time_per_epoch\",\n",
        "    \"speedup_total_train_time\"\n",
        "]\n",
        "\n",
        "eff_summary = (\n",
        "    runs_df.groupby(\"tau_BCS\")[eff_cols]\n",
        "           .agg([\"mean\", \"std\"])\n",
        ")\n",
        "eff_summary.columns = [f\"{m}_{s}\" for m, s in eff_summary.columns]\n",
        "eff_summary = eff_summary.reset_index()\n",
        "\n",
        "# Friendly units\n",
        "eff_summary[\"train_time_min_mean\"] = (eff_summary[\"train_time_sec_mean\"] / 60.0).round(2)\n",
        "eff_summary[\"train_time_min_std\"]  = (eff_summary[\"train_time_sec_std\"] / 60.0).round(2)\n",
        "\n",
        "# Round other fields\n",
        "for c in eff_summary.columns:\n",
        "    if c != \"tau_BCS\":\n",
        "        eff_summary[c] = pd.to_numeric(eff_summary[c], errors=\"ignore\")\n",
        "eff_summary = eff_summary.round(4)\n",
        "\n",
        "# Save + print\n",
        "eff_path = OUT_ROOT / \"yolo_efficiency_gains_mean_std.csv\"\n",
        "eff_summary.to_csv(eff_path, index=False)\n",
        "\n",
        "print(\"\\n=== EFFICIENCY GAINS (mean ± std) ===\")\n",
        "print(eff_summary.to_string(index=False))\n",
        "print(\"\\nSaved efficiency gains table to:\", eff_path)\n"
      ],
      "metadata": {
        "id": "tlYCPW6rnBXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def folder_size_gb(p: Path) -> float:\n",
        "    total = 0\n",
        "    for fp in p.rglob(\"*\"):\n",
        "        if fp.is_file():\n",
        "            total += fp.stat().st_size\n",
        "    return total / (1024**3)\n",
        "\n",
        "baseline_size = folder_size_gb(Path(baseline_info[\"dataset_dir\"]))\n",
        "print(\"Baseline dataset size (GB):\", round(baseline_size, 3))\n",
        "\n",
        "for tau in TAUS_REPORTED:\n",
        "    pr_dir = Path(PRUNED_INFOS[tau][\"dataset_dir\"])\n",
        "    pr_size = folder_size_gb(pr_dir)\n",
        "    print(f\"tau={tau}: size(GB)={round(pr_size,3)} | savings={round((1-pr_size/baseline_size)*100,2)}%\")\n"
      ],
      "metadata": {
        "id": "uP7yKZOanBQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NEW CELL A — Storage footprint + dataset label/image counts\n",
        "# ============================================================\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def folder_size_gb(p: Path) -> float:\n",
        "    total = 0\n",
        "    for fp in p.rglob(\"*\"):\n",
        "        if fp.is_file():\n",
        "            total += fp.stat().st_size\n",
        "    return total / (1024**3)\n",
        "\n",
        "def count_images_labels(dataset_dir: Path, split: str) -> dict:\n",
        "    img_dir = dataset_dir / \"images\" / split\n",
        "    lbl_dir = dataset_dir / \"labels\" / split\n",
        "    n_imgs = sum(1 for _ in img_dir.glob(\"*.jpg\")) + sum(1 for _ in img_dir.glob(\"*.png\")) + sum(1 for _ in img_dir.glob(\"*.jpeg\"))\n",
        "    n_lbl_files = sum(1 for _ in lbl_dir.glob(\"*.txt\"))\n",
        "    n_labels = 0\n",
        "    for p in lbl_dir.glob(\"*.txt\"):\n",
        "        with open(p, \"r\") as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    n_labels += 1\n",
        "    return {\"n_images\": n_imgs, \"n_label_files\": n_lbl_files, \"n_labels\": n_labels}\n",
        "\n",
        "baseline_dir = Path(baseline_info[\"dataset_dir\"])\n",
        "\n",
        "rows = []\n",
        "base_size = folder_size_gb(baseline_dir)\n",
        "base_train = count_images_labels(baseline_dir, \"train\")\n",
        "base_val   = count_images_labels(baseline_dir, \"val\")\n",
        "\n",
        "rows.append({\n",
        "    \"condition\": \"baseline_unpruned\",\n",
        "    \"tau\": \"unpruned\",\n",
        "    \"size_gb\": base_size,\n",
        "    \"train_images\": base_train[\"n_images\"],\n",
        "    \"train_labels\": base_train[\"n_labels\"],\n",
        "    \"val_images\": base_val[\"n_images\"],\n",
        "    \"val_labels\": base_val[\"n_labels\"],\n",
        "})\n",
        "\n",
        "for tau in TAUS_REPORTED:\n",
        "    d = Path(PRUNED_INFOS[tau][\"dataset_dir\"])\n",
        "    size_gb = folder_size_gb(d)\n",
        "    tr = count_images_labels(d, \"train\")\n",
        "    va = count_images_labels(d, \"val\")\n",
        "    rows.append({\n",
        "        \"condition\": f\"bcs_pruned_tau{tau:.1f}\",\n",
        "        \"tau\": float(tau),\n",
        "        \"size_gb\": size_gb,\n",
        "        \"train_images\": tr[\"n_images\"],\n",
        "        \"train_labels\": tr[\"n_labels\"],\n",
        "        \"val_images\": va[\"n_images\"],\n",
        "        \"val_labels\": va[\"n_labels\"],\n",
        "    })\n",
        "\n",
        "df_size = pd.DataFrame(rows)\n",
        "df_size[\"storage_savings_vs_base_pct\"] = (1 - df_size[\"size_gb\"] / base_size) * 100\n",
        "df_size[\"train_label_reduction_vs_base_pct\"] = (1 - df_size[\"train_labels\"] / base_train[\"n_labels\"]) * 100\n",
        "\n",
        "print(df_size.to_string(index=False))\n",
        "save_path = Path(OUT_ROOT) / \"dataset_storage_and_counts.csv\"\n",
        "df_size.to_csv(save_path, index=False)\n",
        "print(\"\\nSaved:\", save_path)\n"
      ],
      "metadata": {
        "id": "wx6Y6GDUp-Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NEW CELL B — Fine-grained label shift (class / camera / size bins)\n",
        "# ============================================================\n",
        "\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "def parse_labels_with_meta(labels_dir: Path) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Returns rows: cam, cls, area (w*h), file\n",
        "    Expects filenames like: {log_id}_{cam}_{ts}.txt\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for p in labels_dir.glob(\"*.txt\"):\n",
        "        m = re.match(r\"(.+?)_(.+?)_(\\d+)\\.txt$\", p.name)\n",
        "        cam = m.group(2) if m else \"UNKNOWN\"\n",
        "        with open(p, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) != 5:\n",
        "                    continue\n",
        "                cls = int(parts[0])\n",
        "                w = float(parts[3]); h = float(parts[4])\n",
        "                area = w * h\n",
        "                rows.append({\"cam\": cam, \"cls\": cls, \"area\": area, \"file\": p.name})\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "def size_bin(area: float) -> str:\n",
        "    # YOLO normalized area: typical small objects are tiny.\n",
        "    # You can adjust thresholds; these are reasonable defaults.\n",
        "    if area < 0.0025:\n",
        "        return \"small\"\n",
        "    elif area < 0.02:\n",
        "        return \"medium\"\n",
        "    else:\n",
        "        return \"large\"\n",
        "\n",
        "def summarize_shifts(base_df: pd.DataFrame, other_df: pd.DataFrame, label: str) -> dict:\n",
        "    out = {}\n",
        "\n",
        "    # overall\n",
        "    out[\"label\"] = label\n",
        "    out[\"n_base\"] = len(base_df)\n",
        "    out[\"n_other\"] = len(other_df)\n",
        "    out[\"pct_change\"] = 100 * (len(other_df) / max(len(base_df), 1) - 1)\n",
        "\n",
        "    # class distribution shift\n",
        "    base_cls = base_df[\"cls\"].value_counts(normalize=True)\n",
        "    oth_cls  = other_df[\"cls\"].value_counts(normalize=True)\n",
        "    cls_cmp = pd.concat([base_cls.rename(\"base\"), oth_cls.rename(\"other\")], axis=1).fillna(0.0)\n",
        "    cls_cmp[\"abs_diff\"] = (cls_cmp[\"other\"] - cls_cmp[\"base\"]).abs()\n",
        "    out[\"top_class_shift\"] = cls_cmp.sort_values(\"abs_diff\", ascending=False).head(10)\n",
        "\n",
        "    # camera distribution shift\n",
        "    base_cam = base_df[\"cam\"].value_counts(normalize=True)\n",
        "    oth_cam  = other_df[\"cam\"].value_counts(normalize=True)\n",
        "    cam_cmp = pd.concat([base_cam.rename(\"base\"), oth_cam.rename(\"other\")], axis=1).fillna(0.0)\n",
        "    cam_cmp[\"abs_diff\"] = (cam_cmp[\"other\"] - cam_cmp[\"base\"]).abs()\n",
        "    out[\"top_camera_shift\"] = cam_cmp.sort_values(\"abs_diff\", ascending=False).head(10)\n",
        "\n",
        "    # size-bin shift\n",
        "    base_sizes = base_df[\"size_bin\"].value_counts(normalize=True)\n",
        "    oth_sizes  = other_df[\"size_bin\"].value_counts(normalize=True)\n",
        "    size_cmp = pd.concat([base_sizes.rename(\"base\"), oth_sizes.rename(\"other\")], axis=1).fillna(0.0)\n",
        "    size_cmp[\"abs_diff\"] = (size_cmp[\"other\"] - size_cmp[\"base\"]).abs()\n",
        "    out[\"size_bin_shift\"] = size_cmp.sort_values(\"abs_diff\", ascending=False)\n",
        "\n",
        "    return out\n",
        "\n",
        "baseline_dir = Path(baseline_info[\"dataset_dir\"])\n",
        "base_train_df = parse_labels_with_meta(baseline_dir / \"labels\" / \"train\")\n",
        "base_train_df[\"size_bin\"] = base_train_df[\"area\"].apply(size_bin)\n",
        "\n",
        "for tau in TAUS_REPORTED:\n",
        "    pr_dir = Path(PRUNED_INFOS[tau][\"dataset_dir\"])\n",
        "    pr_train_df = parse_labels_with_meta(pr_dir / \"labels\" / \"train\")\n",
        "    pr_train_df[\"size_bin\"] = pr_train_df[\"area\"].apply(size_bin)\n",
        "\n",
        "    s = summarize_shifts(base_train_df, pr_train_df, label=f\"BCS tau={tau:.1f}\")\n",
        "\n",
        "    print(\"\\n==============================\")\n",
        "    print(f\"SHIFT SUMMARY — {s['label']}\")\n",
        "    print(\"Overall labels: base =\", s[\"n_base\"], \"| other =\", s[\"n_other\"], f\"| pct change = {s['pct_change']:.2f}%\")\n",
        "    print(\"\\nTop class distribution shifts (abs diff in share):\")\n",
        "    print(s[\"top_class_shift\"].to_string())\n",
        "    print(\"\\nTop camera distribution shifts (abs diff in share):\")\n",
        "    print(s[\"top_camera_shift\"].to_string())\n",
        "    print(\"\\nSize-bin share shift:\")\n",
        "    print(s[\"size_bin_shift\"].to_string())\n"
      ],
      "metadata": {
        "id": "YgfsxEQfp_xW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NEW CELL C — Random label-removal baselines matched to BCS deletion rates\n",
        "# ============================================================\n",
        "\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "def update_yaml_path(data_yaml_path: Path, new_dataset_dir: Path):\n",
        "    # Replace the first \"path:\" line in data.yaml\n",
        "    lines = data_yaml_path.read_text().splitlines()\n",
        "    new_lines = []\n",
        "    for ln in lines:\n",
        "        if ln.startswith(\"path:\"):\n",
        "            new_lines.append(f\"path: {new_dataset_dir}\")\n",
        "        else:\n",
        "            new_lines.append(ln)\n",
        "    data_yaml_path.write_text(\"\\n\".join(new_lines) + \"\\n\")\n",
        "\n",
        "def compute_train_label_count(dataset_dir: Path) -> int:\n",
        "    lbl_dir = dataset_dir / \"labels\" / \"train\"\n",
        "    n = 0\n",
        "    for p in lbl_dir.glob(\"*.txt\"):\n",
        "        with open(p, \"r\") as f:\n",
        "            for line in f:\n",
        "                if line.strip():\n",
        "                    n += 1\n",
        "    return n\n",
        "\n",
        "def clone_and_random_prune_train_labels(\n",
        "    baseline_dir: Path,\n",
        "    out_dir: Path,\n",
        "    drop_rate: float,\n",
        "    seed: int\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Copies entire baseline dataset to out_dir, then randomly deletes TRAIN label lines\n",
        "    with probability drop_rate. VAL remains unpruned (important for your eval protocol).\n",
        "    \"\"\"\n",
        "    out_dir = Path(out_dir)\n",
        "    if out_dir.exists():\n",
        "        shutil.rmtree(out_dir)\n",
        "    shutil.copytree(baseline_dir, out_dir)\n",
        "\n",
        "    rng = np.random.RandomState(seed)\n",
        "\n",
        "    train_lbl_dir = out_dir / \"labels\" / \"train\"\n",
        "    for p in train_lbl_dir.glob(\"*.txt\"):\n",
        "        with open(p, \"r\") as f:\n",
        "            lines = [ln for ln in f.read().splitlines() if ln.strip()]\n",
        "\n",
        "        if not lines:\n",
        "            continue\n",
        "\n",
        "        keep = []\n",
        "        for ln in lines:\n",
        "            if rng.rand() >= drop_rate:\n",
        "                keep.append(ln)\n",
        "\n",
        "        # Write back (allow empty label files; YOLO can handle)\n",
        "        with open(p, \"w\") as f:\n",
        "            f.write(\"\\n\".join(keep))\n",
        "\n",
        "    # Fix data.yaml path\n",
        "    yaml_path = out_dir / \"data.yaml\"\n",
        "    update_yaml_path(yaml_path, out_dir)\n",
        "\n",
        "    return out_dir\n",
        "\n",
        "baseline_dir = Path(baseline_info[\"dataset_dir\"])\n",
        "base_train_labels = compute_train_label_count(baseline_dir)\n",
        "print(\"Baseline train label lines:\", base_train_labels)\n",
        "\n",
        "RANDOM_INFOS = {}  # tau -> {seed -> dataset_dir}\n",
        "RANDOM_DROP_RATES = {}\n",
        "\n",
        "# Define drop rate to MATCH BCS overall deletion fraction\n",
        "# Use build-time stats: deleted / before\n",
        "for tau in TAUS_REPORTED:\n",
        "    before = PRUNED_INFOS[tau][\"total_candidate_labels_before_pruning\"]\n",
        "    deleted = PRUNED_INFOS[tau][\"total_deleted_label_instances\"]\n",
        "    drop_rate = float(deleted / max(before, 1))\n",
        "    RANDOM_DROP_RATES[tau] = drop_rate\n",
        "    print(f\"tau={tau:.1f} -> matched random drop_rate={drop_rate:.4f} ({drop_rate*100:.2f}%)\")\n",
        "\n",
        "# Build one random dataset per tau per seed (so random baseline also gets multi-seed)\n",
        "SEEDS = [7, 17, 27]  # keep consistent\n",
        "for tau in TAUS_REPORTED:\n",
        "    RANDOM_INFOS[tau] = {}\n",
        "    for seed in SEEDS:\n",
        "        out_dir = Path(OUT_ROOT) / f\"random_pruned_tau{tau:.1f}_seed{seed}\"\n",
        "        built_dir = clone_and_random_prune_train_labels(\n",
        "            baseline_dir=baseline_dir,\n",
        "            out_dir=out_dir,\n",
        "            drop_rate=RANDOM_DROP_RATES[tau],\n",
        "            seed=seed\n",
        "        )\n",
        "        RANDOM_INFOS[tau][seed] = built_dir\n",
        "        print(\"Built random baseline:\", built_dir)\n"
      ],
      "metadata": {
        "id": "y0kgS1iuqFHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# NEW CELL D — Multi-seed: Baseline vs BCS vs Random + per-class metrics\n",
        "# ============================================================\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "\n",
        "# If you did not run diagnostic ES, set this manually:\n",
        "if \"EPOCHS_FINAL\" not in globals():\n",
        "    EPOCHS_FINAL = 30\n",
        "\n",
        "EPOCHS = int(EPOCHS_FINAL)\n",
        "IMGSZ = 640\n",
        "BATCH = 16\n",
        "SEEDS = [7, 17, 27]\n",
        "\n",
        "DEVICE = 0 if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"DEVICE:\", DEVICE, \"| EPOCHS:\", EPOCHS, \"| SEEDS:\", SEEDS)\n",
        "\n",
        "BASELINE_DIR = Path(baseline_info[\"dataset_dir\"])\n",
        "EVAL_DIR = BASELINE_DIR  # always eval on unpruned\n",
        "\n",
        "def extract_per_class(metrics_obj):\n",
        "    \"\"\"\n",
        "    Tries to robustly extract:\n",
        "    - class indices\n",
        "    - per-class AP50\n",
        "    - per-class AP50-95\n",
        "    Ultralytics versions differ, so we check multiple attribute names.\n",
        "    \"\"\"\n",
        "    box = getattr(metrics_obj, \"box\", None)\n",
        "    if box is None:\n",
        "        return None\n",
        "\n",
        "    # class indices\n",
        "    cls_idx = getattr(box, \"ap_class_index\", None)\n",
        "    if cls_idx is None:\n",
        "        cls_idx = getattr(box, \"cls\", None)  # fallback in some versions\n",
        "\n",
        "    # per-class mAP50-95 often in box.maps\n",
        "    ap5095 = getattr(box, \"maps\", None)\n",
        "\n",
        "    # per-class mAP50 sometimes in box.map50s or box.ap50\n",
        "    ap50 = getattr(box, \"map50s\", None)\n",
        "    if ap50 is None:\n",
        "        ap50 = getattr(box, \"ap50\", None)\n",
        "\n",
        "    # last resort: if only maps exists, still return that\n",
        "    if cls_idx is None or ap5095 is None:\n",
        "        return None\n",
        "\n",
        "    cls_idx = list(map(int, list(cls_idx)))\n",
        "    ap5095 = list(map(float, list(ap5095)))\n",
        "\n",
        "    if ap50 is not None:\n",
        "        ap50 = list(map(float, list(ap50)))\n",
        "        if len(ap50) != len(cls_idx):\n",
        "            ap50 = None\n",
        "\n",
        "    return {\"cls_idx\": cls_idx, \"ap50\": ap50, \"ap5095\": ap5095}\n",
        "\n",
        "def train_eval_one(train_dir: Path, run_name: str, seed: int):\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    train_res = model.train(\n",
        "        data=str(train_dir / \"data.yaml\"),\n",
        "        epochs=EPOCHS,\n",
        "        imgsz=IMGSZ,\n",
        "        batch=BATCH,\n",
        "        device=DEVICE,\n",
        "        cache=True,\n",
        "        workers=4,\n",
        "        name=run_name,\n",
        "        project=str(train_dir / \"runs_review\"),\n",
        "        seed=seed,\n",
        "        verbose=False,\n",
        "    )\n",
        "    t1 = time.time()\n",
        "\n",
        "    metrics = model.val(\n",
        "        data=str(EVAL_DIR / \"data.yaml\"),\n",
        "        device=DEVICE,\n",
        "        verbose=False\n",
        "    )\n",
        "    t2 = time.time()\n",
        "\n",
        "    # Global metrics\n",
        "    precision = float(metrics.box.mp)\n",
        "    recall    = float(metrics.box.mr)\n",
        "    map50     = float(metrics.box.map50)\n",
        "    map5095   = float(metrics.box.map)\n",
        "    f1        = 2 * precision * recall / (precision + recall + 1e-12)\n",
        "\n",
        "    # Epochs actually ran\n",
        "    epochs_ran = EPOCHS\n",
        "    results_csv = Path(train_res.save_dir) / \"results.csv\"\n",
        "    if results_csv.exists():\n",
        "        df = pd.read_csv(results_csv)\n",
        "        epochs_ran = len(df)\n",
        "\n",
        "    train_time = (t1 - t0)\n",
        "    time_per_epoch = train_time / max(epochs_ran, 1)\n",
        "\n",
        "    # Per-class\n",
        "    per_cls = extract_per_class(metrics)\n",
        "\n",
        "    return {\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-Score\": float(f1),\n",
        "        \"mAP50\": map50,\n",
        "        \"mAP50-95\": map5095,\n",
        "        \"train_time_sec\": float(train_time),\n",
        "        \"time_per_epoch_sec\": float(time_per_epoch),\n",
        "        \"epochs_ran\": int(epochs_ran),\n",
        "        \"per_class\": per_cls\n",
        "    }\n",
        "\n",
        "# ---------- Run all conditions ----------\n",
        "all_runs = []\n",
        "per_class_rows = []\n",
        "\n",
        "# Baseline\n",
        "for seed in SEEDS:\n",
        "    out = train_eval_one(BASELINE_DIR, f\"baseline_seed{seed}\", seed)\n",
        "    all_runs.append({\n",
        "        \"condition\": \"baseline\",\n",
        "        \"tau\": \"unpruned\",\n",
        "        \"seed\": seed,\n",
        "        **{k: out[k] for k in [\"Precision\",\"Recall\",\"F1-Score\",\"mAP50\",\"mAP50-95\",\"train_time_sec\",\"time_per_epoch_sec\",\"epochs_ran\"]}\n",
        "    })\n",
        "    if out[\"per_class\"] is not None:\n",
        "        for i, cls_id in enumerate(out[\"per_class\"][\"cls_idx\"]):\n",
        "            per_class_rows.append({\n",
        "                \"condition\": \"baseline\",\n",
        "                \"tau\": \"unpruned\",\n",
        "                \"seed\": seed,\n",
        "                \"cls_id\": cls_id,\n",
        "                \"AP50\": (out[\"per_class\"][\"ap50\"][i] if out[\"per_class\"][\"ap50\"] is not None else np.nan),\n",
        "                \"AP50-95\": out[\"per_class\"][\"ap5095\"][i],\n",
        "            })\n",
        "\n",
        "# BCS pruned\n",
        "for tau in TAUS_REPORTED:\n",
        "    train_dir = Path(PRUNED_INFOS[tau][\"dataset_dir\"])\n",
        "    for seed in SEEDS:\n",
        "        out = train_eval_one(train_dir, f\"bcs_tau{tau:.1f}_seed{seed}\", seed)\n",
        "        all_runs.append({\n",
        "            \"condition\": \"bcs\",\n",
        "            \"tau\": float(tau),\n",
        "            \"seed\": seed,\n",
        "            **{k: out[k] for k in [\"Precision\",\"Recall\",\"F1-Score\",\"mAP50\",\"mAP50-95\",\"train_time_sec\",\"time_per_epoch_sec\",\"epochs_ran\"]}\n",
        "        })\n",
        "        if out[\"per_class\"] is not None:\n",
        "            for i, cls_id in enumerate(out[\"per_class\"][\"cls_idx\"]):\n",
        "                per_class_rows.append({\n",
        "                    \"condition\": \"bcs\",\n",
        "                    \"tau\": float(tau),\n",
        "                    \"seed\": seed,\n",
        "                    \"cls_id\": cls_id,\n",
        "                    \"AP50\": (out[\"per_class\"][\"ap50\"][i] if out[\"per_class\"][\"ap50\"] is not None else np.nan),\n",
        "                    \"AP50-95\": out[\"per_class\"][\"ap5095\"][i],\n",
        "                })\n",
        "\n",
        "# Random pruned (matched-rate baseline)\n",
        "# Uses RANDOM_INFOS[tau][seed] built in NEW CELL C\n",
        "for tau in TAUS_REPORTED:\n",
        "    for seed in SEEDS:\n",
        "        train_dir = Path(RANDOM_INFOS[tau][seed])\n",
        "        out = train_eval_one(train_dir, f\"random_tau{tau:.1f}_seed{seed}\", seed)\n",
        "        all_runs.append({\n",
        "            \"condition\": \"random\",\n",
        "            \"tau\": float(tau),\n",
        "            \"seed\": seed,\n",
        "            **{k: out[k] for k in [\"Precision\",\"Recall\",\"F1-Score\",\"mAP50\",\"mAP50-95\",\"train_time_sec\",\"time_per_epoch_sec\",\"epochs_ran\"]}\n",
        "        })\n",
        "        if out[\"per_class\"] is not None:\n",
        "            for i, cls_id in enumerate(out[\"per_class\"][\"cls_idx\"]):\n",
        "                per_class_rows.append({\n",
        "                    \"condition\": \"random\",\n",
        "                    \"tau\": float(tau),\n",
        "                    \"seed\": seed,\n",
        "                    \"cls_id\": cls_id,\n",
        "                    \"AP50\": (out[\"per_class\"][\"ap50\"][i] if out[\"per_class\"][\"ap50\"] is not None else np.nan),\n",
        "                    \"AP50-95\": out[\"per_class\"][\"ap5095\"][i],\n",
        "                })\n",
        "\n",
        "runs_df = pd.DataFrame(all_runs)\n",
        "raw_path = Path(OUT_ROOT) / \"review_multiseed_baseline_bcs_random_raw.csv\"\n",
        "runs_df.to_csv(raw_path, index=False)\n",
        "print(\"\\nSaved raw run table:\", raw_path)\n",
        "\n",
        "# ---------- Summary tables ----------\n",
        "metric_cols = [\"mAP50\",\"mAP50-95\",\"Precision\",\"Recall\",\"F1-Score\"]\n",
        "eff_cols = [\"time_per_epoch_sec\",\"train_time_sec\"]\n",
        "\n",
        "summary = (\n",
        "    runs_df.groupby([\"condition\",\"tau\"])[metric_cols + eff_cols]\n",
        "          .agg([\"mean\",\"std\"])\n",
        ")\n",
        "summary.columns = [f\"{m}_{s}\" for m,s in summary.columns]\n",
        "summary = summary.reset_index()\n",
        "summary = summary.round(4)\n",
        "\n",
        "# speedups vs baseline (mean baseline time_per_epoch)\n",
        "base_tpe = float(runs_df[runs_df[\"condition\"]==\"baseline\"][\"time_per_epoch_sec\"].mean())\n",
        "summary[\"speedup_time_per_epoch_mean\"] = (base_tpe / summary[\"time_per_epoch_sec_mean\"]).round(4)\n",
        "\n",
        "sum_path = Path(OUT_ROOT) / \"review_summary_mean_std.csv\"\n",
        "summary.to_csv(sum_path, index=False)\n",
        "print(\"\\n=== SUMMARY (mean ± std) ===\")\n",
        "print(summary.to_string(index=False))\n",
        "print(\"\\nSaved summary:\", sum_path)\n",
        "\n",
        "# ---------- Per-class summary ----------\n",
        "if len(per_class_rows) > 0:\n",
        "    pc_df = pd.DataFrame(per_class_rows)\n",
        "\n",
        "    # Map class id -> name from your global names list\n",
        "    id2name = {i: n for i, n in enumerate(NAMES)}\n",
        "    pc_df[\"class_name\"] = pc_df[\"cls_id\"].map(id2name)\n",
        "\n",
        "    pc_summary = (\n",
        "        pc_df.groupby([\"condition\",\"tau\",\"cls_id\",\"class_name\"])[[\"AP50\",\"AP50-95\"]]\n",
        "            .agg([\"mean\",\"std\"])\n",
        "    )\n",
        "    pc_summary.columns = [f\"{m}_{s}\" for m,s in pc_summary.columns]\n",
        "    pc_summary = pc_summary.reset_index().round(4)\n",
        "\n",
        "    pc_path = Path(OUT_ROOT) / \"per_class_AP_mean_std.csv\"\n",
        "    pc_summary.to_csv(pc_path, index=False)\n",
        "\n",
        "    print(\"\\n=== PER-CLASS AP (mean ± std) ===\")\n",
        "    print(pc_summary.head(30).to_string(index=False))\n",
        "    print(\"\\nSaved per-class table:\", pc_path)\n",
        "else:\n",
        "    print(\"\\n[WARN] Per-class metrics could not be extracted from this Ultralytics version.\")\n",
        "    print(\"If you see this, tell me your ultralytics version and I will adapt extractor to that exact API.\")\n"
      ],
      "metadata": {
        "id": "s3HKEk3sqFzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lcExr8nfqMPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6tggHQbSp_uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5WaxXC7Np_q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5dKrpdZop_nI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}